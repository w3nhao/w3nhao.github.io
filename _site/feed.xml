<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://w3nhao.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://w3nhao.github.io/" rel="alternate" type="text/html" /><updated>2025-10-15T00:54:05+01:00</updated><id>https://w3nhao.github.io/feed.xml</id><title type="html">Wenhao Deng</title><subtitle></subtitle><author><name>Wenhao Deng</name><email>wenhao.deng@foxmail.com</email></author><entry><title type="html">HR, NDCG, and MRR: An easy implementation with TorchMetrics</title><link href="https://w3nhao.github.io/2023/03/31/HR-MRR-NDCG-Torchmetric-Implementation/" rel="alternate" type="text/html" title="HR, NDCG, and MRR: An easy implementation with TorchMetrics" /><published>2023-03-31T00:00:00+01:00</published><updated>2023-03-31T00:00:00+01:00</updated><id>https://w3nhao.github.io/2023/03/31/HR-MRR-NDCG-Torchmetric-Implementation</id><content type="html" xml:base="https://w3nhao.github.io/2023/03/31/HR-MRR-NDCG-Torchmetric-Implementation/"><![CDATA[<p>To assess the performance of  Recommender systems, we need to have reliable evaluation metrics. In this blog post, we will discuss three popular metrics: Hit Rate (HR), Normalized Discounted Cumulative Gain (NDCG), and Mean Reciprocal Rank (MRR). We will also show you how to easily implement these metrics using TorchMetrics and integrate them into a PyTorch Lightning model.</p>

<h2 id="0-understanding-the-get_topk_ranks-function">0. Understanding the <code class="language-plaintext highlighter-rouge">get_topk_ranks</code> Function</h2>

<p>In the context of our recommender system evaluation, it is essential to understand the <code class="language-plaintext highlighter-rouge">get_topk_ranks</code> function, which plays a crucial role in computing the ranks of the target items in the predicted scores. This function is used as an intermediate step to calculate the HR, NDCG, and MRR metrics.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">get_topk_ranks</span><span class="p">(</span><span class="n">pred_scores</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">topk</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s"> get topk ranks of the target in the pred_scores
    Args:
        pred_scores: (batch_size, item_num(with padding item))
        target: (batch_size, ) or (batch_size, 1)
        topk: int
        
    Returns:
        topk_rank: (batch_size, 1) topk + 1 if not hit, 1 is the first rank
    </span><span class="sh">"""</span>
    <span class="k">assert</span> <span class="n">target</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">pred_scores</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">assert</span> <span class="n">pred_scores</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">topk</span>
    <span class="n">target</span> <span class="o">=</span> <span class="n">target</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="n">target</span><span class="p">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">target</span>

    <span class="n">_</span><span class="p">,</span> <span class="n">topk_idx</span> <span class="o">=</span> <span class="n">pred_scores</span><span class="p">.</span><span class="nf">topk</span><span class="p">(</span><span class="n">topk</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">hitted_row</span><span class="p">,</span> <span class="n">rank</span> <span class="o">=</span> <span class="p">(</span><span class="n">target</span> <span class="o">==</span> <span class="n">topk_idx</span><span class="p">).</span><span class="nf">nonzero</span><span class="p">().</span><span class="nf">split</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">rank</span> <span class="o">+=</span> <span class="mi">1</span>
    
    <span class="c1"># first set all rank to maximum value 
</span>    <span class="c1"># int64 or set all rank to topk + 1
</span>    <span class="n">all_rank</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">full_like</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">topk</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="c1"># then set the hitted row to the rank
</span>    <span class="n">all_rank</span> <span class="o">=</span> <span class="n">all_rank</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">hitted_row</span><span class="p">,</span> <span class="n">rank</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">all_rank</span>
</code></pre></div></div>

<h3 id="the-get_topk_ranks-function-explained">The <code class="language-plaintext highlighter-rouge">get_topk_ranks</code> Function Explained</h3>

<p>The <code class="language-plaintext highlighter-rouge">get_topk_ranks</code> function takes three arguments: <code class="language-plaintext highlighter-rouge">pred_scores</code>, <code class="language-plaintext highlighter-rouge">target</code>, and <code class="language-plaintext highlighter-rouge">topk</code>. It returns the ranks of the target items within the top-k predictions.</p>

<ol>
  <li>
    <p><code class="language-plaintext highlighter-rouge">pred_scores</code>: A tensor of shape <code class="language-plaintext highlighter-rouge">(batch_size, item_num(with padding item))</code>, representing the predicted scores for each item for all users in a batch.</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">target</code>: A tensor of shape <code class="language-plaintext highlighter-rouge">(batch_size,)</code> or <code class="language-plaintext highlighter-rouge">(batch_size, 1)</code>, containing the ground truth target items for each user in the batch.</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">topk</code>: An integer value representing the number of top items we want to consider.</p>
  </li>
</ol>

<p>The function returns a tensor <code class="language-plaintext highlighter-rouge">topk_rank</code> of shape <code class="language-plaintext highlighter-rouge">(batch_size, 1)</code> containing the top-k ranks of the target items in the predicted scores. If a target item is not in the top-k predictions, the rank will be set to <code class="language-plaintext highlighter-rouge">topk + 1</code>.</p>

<h3 id="how-the-get_topk_ranks-function-works">How the <code class="language-plaintext highlighter-rouge">get_topk_ranks</code> Function Works</h3>

<p>The <code class="language-plaintext highlighter-rouge">get_topk_ranks</code> function follows these steps to compute the ranks:</p>

<ol>
  <li>
    <p>Ensures that the target tensor has two dimensions by unsqueezing it if necessary.</p>
  </li>
  <li>
    <p>Retrieves the indices of the top-k items in the predicted scores using the <code class="language-plaintext highlighter-rouge">topk()</code> method.</p>
  </li>
  <li>
    <p>Computes the ranks of the target items within the top-k predictions by checking if the target item is present in the top-k indices.</p>
  </li>
  <li>
    <p>Initializes a tensor <code class="language-plaintext highlighter-rouge">all_rank</code> with the same shape as the target tensor, filled with the value <code class="language-plaintext highlighter-rouge">topk + 1</code>.</p>
  </li>
  <li>
    <p>Updates the <code class="language-plaintext highlighter-rouge">all_rank</code> tensor with the computed ranks for each user using the <code class="language-plaintext highlighter-rouge">scatter()</code> method.</p>
  </li>
</ol>

<p>By using the <code class="language-plaintext highlighter-rouge">get_topk_ranks</code> function, we can efficiently compute the top-k ranks for each user in a batch, which is an essential step for calculating HR, NDCG, and MRR metrics in our recommender system evaluation.</p>

<h2 id="1-hit-rate-hr">1. Hit Rate (HR)</h2>

<p>Hit Rate is a simple and intuitive metric that measures the proportion of relevant items recommended to the user.</p>

<p><strong>Mathematical Definition:</strong></p>

<p>HR@k = (Number of hits in the top-k recommendations) / (Total number of recommendations)</p>

<p>The Hit Ratio (HR) is a binary metric that measures whether a relevant item is present in the top-k recommendations or not. Mathematically, it can be expressed as:</p>

<p>$$\text{HR@k} = \frac{1}{|U|}\sum_{u=1}^{|U|} \text{hit}_u
$$</p>

<p>
where $|U|$ is the number of users, and $\text{hit}_u$ is 1 if the ground truth item is present in the top-k recommendations for user $u$, and 0 otherwise.
</p>

<p><strong>TorchMetrics Implementation:</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">torchmetrics</span> <span class="kn">import</span> <span class="n">Metric</span>

<span class="k">class</span> <span class="nc">HR</span><span class="p">(</span><span class="n">Metric</span><span class="p">):</span>
    <span class="bp">...</span>
    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">topk_rank</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">accumulate_count</span> <span class="o">+=</span> <span class="n">topk_rank</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">self</span><span class="p">.</span><span class="n">accumulate_metric</span> <span class="o">+=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_metric</span><span class="p">(</span><span class="n">topk_rank</span><span class="p">[</span><span class="n">topk_rank</span> <span class="o">&lt;=</span> <span class="n">self</span><span class="p">.</span><span class="n">k</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">_metric</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">topk_rank</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">topk_rank</span><span class="p">.</span><span class="nf">numel</span><span class="p">()</span>
</code></pre></div></div>

<h2 id="2-normalized-discounted-cumulative-gain-ndcg">2. Normalized Discounted Cumulative Gain (NDCG)</h2>
<p>NDCG is a metric that measures the quality of the ranking of the recommended items, taking into account their relevance and position in the list.</p>

<p><strong>Mathematical Definition:</strong></p>

<p>Normalized Discounted Cumulative Gain (NDCG) is a measure that evaluates the quality of the ranking of recommended items. It takes into account the positions of relevant items in the top-k recommendations. The NDCG@k is defined as:</p>

<p>NDCG@k = (DCG@k) / (IDCG@k)</p>

<p>where DCG@k is the Discounted Cumulative Gain at position k, and IDCG@k is the Ideal Discounted Cumulative Gain at position k.</p>

<p>DCG@k = sum(relevance_i / log2(i + 1)) for i in range(1, k + 1)</p>

<p>$$\text{NDCG@k} = \frac{1}{|U|} \sum_{u=1}^{|U|} \frac{\sum_{i=1}^{k} \frac{2^{\text{rel}_i(u)} - 1}{\log_2{(i+1)}}}{\text{IDCG}_u}
$$</p>

<p>
where $|U|$ is the number of users, $\text{rel}_i(u)$ is the relevance score of item $i$ for user $u$, and $\text{IDCG}_u$ is the Ideal Discounted Cumulative Gain for user $u$, which is the maximum possible NDCG for that user.
</p>

<p><strong>TorchMetrics Implementation:</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">torchmetrics</span> <span class="kn">import</span> <span class="n">Metric</span>

<span class="k">class</span> <span class="nc">NDCG</span><span class="p">(</span><span class="n">Metric</span><span class="p">):</span>
    <span class="bp">...</span>
    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">topk_rank</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">accumulate_count</span> <span class="o">+=</span> <span class="n">topk_rank</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">self</span><span class="p">.</span><span class="n">accumulate_metric</span> <span class="o">+=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_metric</span><span class="p">(</span><span class="n">topk_rank</span><span class="p">[</span><span class="n">topk_rank</span> <span class="o">&lt;=</span> <span class="n">self</span><span class="p">.</span><span class="n">k</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">_metric</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">topk_rank</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">torch</span><span class="p">.</span><span class="nf">log2</span><span class="p">(</span><span class="n">topk_rank</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
</code></pre></div></div>

<h2 id="3-mean-reciprocal-rank-mrr">3. Mean Reciprocal Rank (MRR)</h2>
<p>MRR is a metric that measures the quality of the ranking of the recommended items by computing the average of the reciprocal ranks of the first relevant item in the list.</p>

<p><strong>Mathematical Definition:</strong></p>

<p>Mean Reciprocal Rank (MRR) is another metric that evaluates the ranking quality of recommended items. It is the average of the reciprocal of the rank of the first relevant item in the top-k recommendations for each user. MRR can be defined as:</p>

<p>MRR@k = (1 / Number of users) * sum(1 / rank_i) for i in range(Number of users)</p>

<p>$$\text{MRR@k} = \frac{1}{|U|}\sum_{u=1}^{|U|} \frac{1}{\text{rank}_u}
$$</p>

<p>
where $|U|$ is the number of users, and $\text{rank}_u$ is the position of the first relevant item in the top-k recommendations for user $u$.
</p>

<p><strong>TorchMetrics Implementation:</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">torchmetrics</span> <span class="kn">import</span> <span class="n">Metric</span>

<span class="k">class</span> <span class="nc">MRR</span><span class="p">(</span><span class="n">Metric</span><span class="p">):</span>
    <span class="bp">...</span>
    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">topk_rank</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">accumulate_count</span> <span class="o">+=</span> <span class="n">topk_rank</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">self</span><span class="p">.</span><span class="n">accumulate_metric</span> <span class="o">+=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_metric</span><span class="p">(</span><span class="n">topk_rank</span><span class="p">[</span><span class="n">topk_rank</span> <span class="o">&lt;=</span> <span class="n">self</span><span class="p">.</span><span class="n">k</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">_metric</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">topk_rank</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">topk_rank</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="integrating-metrics-with-pytorch-lightning">Integrating Metrics with PyTorch Lightning</h2>
<p>Now, let’s demonstrate how to integrate these evaluation metrics into a PyTorch Lightning model using a sample recommender system called SASRec.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pytorch_lightning</span> <span class="k">as</span> <span class="n">pl</span>
<span class="kn">from</span> <span class="n">torchmetrics</span> <span class="kn">import</span> <span class="n">MetricCollection</span>

<span class="k">class</span> <span class="nc">SASRec</span><span class="p">(</span><span class="n">pl</span><span class="p">.</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="p">...):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="bp">...</span>
        <span class="n">self</span><span class="p">.</span><span class="n">topk_list</span> <span class="o">=</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">]</span>
        <span class="n">self</span><span class="p">.</span><span class="n">topk_metric</span> <span class="o">=</span> <span class="n">MetricCollection</span>
        <span class="p">({</span>
            <span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">metric_name</span><span class="si">}</span><span class="s">@</span><span class="si">{</span><span class="n">topk</span><span class="si">}</span><span class="sh">"</span><span class="p">:</span> <span class="nf">globals</span><span class="p">()[</span><span class="n">metric_name</span><span class="p">](</span><span class="n">topk</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">metric_name</span> <span class="ow">in</span> <span class="p">[</span><span class="sh">"</span><span class="s">HR</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">NDCG</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">MRR</span><span class="sh">"</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">topk</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">topk_list</span>
        <span class="p">})</span>

    <span class="k">def</span> <span class="nf">_on_val_test_epoch_start</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">topk</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">topk_list</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">metric_name</span> <span class="ow">in</span> <span class="n">METRIC_LIST</span><span class="p">:</span>
                <span class="n">self</span><span class="p">.</span><span class="n">topk_metric</span><span class="p">[</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">metric_name</span><span class="si">}</span><span class="s">@</span><span class="si">{</span><span class="n">topk</span><span class="si">}</span><span class="sh">"</span><span class="p">].</span><span class="nf">reset</span><span class="p">()</span>

        <span class="n">self</span><span class="p">.</span><span class="nf">register_buffer</span><span class="p">(</span>
            <span class="sh">"</span><span class="s">all_item_embs</span><span class="sh">"</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="nf">item_encoder</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">all_item_ids</span><span class="p">),</span> <span class="n">persistent</span><span class="o">=</span><span class="bp">False</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">on_validation_epoch_start</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="nf">_on_val_test_epoch_start</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">on_test_epoch_start</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="nf">_on_val_test_epoch_start</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_val_test_step</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">stage</span><span class="p">):</span>
        <span class="bp">...</span>

        <span class="n">pred_item_embs</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">forward</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">input_mask</span><span class="p">)</span>
        <span class="n">pred_scores</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">matmul</span><span class="p">(</span><span class="n">pred_item_embs</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">all_item_embs</span><span class="p">.</span><span class="nf">t</span><span class="p">()).</span><span class="nf">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">pred_scores</span> <span class="o">=</span> <span class="n">pred_scores</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">history</span><span class="p">,</span> <span class="o">-</span><span class="nf">float</span><span class="p">(</span><span class="sh">'</span><span class="s">inf</span><span class="sh">'</span><span class="p">))</span>

        <span class="n">target</span> <span class="o">=</span> <span class="n">behavs</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">target</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">topk</span> <span class="o">=</span> <span class="nf">max</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">topk_list</span><span class="p">)</span>
        <span class="n">all_ranks</span> <span class="o">=</span> <span class="nf">get_topk_ranks</span><span class="p">(</span><span class="n">pred_scores</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">topk</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">topk</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">topk_list</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">metric_name</span> <span class="ow">in</span> <span class="n">METRIC_LIST</span><span class="p">:</span>
                <span class="n">metric</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">topk_metric</span><span class="p">[</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">metric_name</span><span class="si">}</span><span class="s">@</span><span class="si">{</span><span class="n">topk</span><span class="si">}</span><span class="sh">"</span><span class="p">]</span>
                <span class="n">metric</span><span class="p">.</span><span class="nf">update</span><span class="p">(</span><span class="n">all_ranks</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">validation_step</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="nf">_val_test_step</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="sh">"</span><span class="s">val</span><span class="sh">"</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="nf">_val_test_step</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="sh">"</span><span class="s">test</span><span class="sh">"</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_val_test_epoch_end</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">stage</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">topk</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">topk_list</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">metric_name</span> <span class="ow">in</span> <span class="n">METRIC_LIST</span><span class="p">:</span>
                <span class="n">score</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">topk_metric</span><span class="p">[</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">metric_name</span><span class="si">}</span><span class="s">@</span><span class="si">{</span><span class="n">topk</span><span class="si">}</span><span class="sh">"</span><span class="p">].</span><span class="nf">compute</span><span class="p">()</span>
                <span class="k">if</span> <span class="n">metric_name</span> <span class="ow">in</span> <span class="p">[</span><span class="sh">"</span><span class="s">HR</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">NDCG</span><span class="sh">"</span><span class="p">]</span> <span class="ow">and</span> <span class="n">topk</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">]:</span>
                    <span class="n">log_on_progress_bar</span> <span class="o">=</span> <span class="bp">True</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">log_on_progress_bar</span> <span class="o">=</span> <span class="bp">False</span>
                <span class="n">self</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">stage</span><span class="si">}</span><span class="s">_</span><span class="si">{</span><span class="n">metric_name</span><span class="si">}</span><span class="s">@</span><span class="si">{</span><span class="n">topk</span><span class="si">}</span><span class="sh">"</span><span class="p">,</span>
                         <span class="n">score</span><span class="p">,</span>
                         <span class="n">on_epoch</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                         <span class="n">prog_bar</span><span class="o">=</span><span class="n">log_on_progress_bar</span><span class="p">,</span>
                         <span class="n">logger</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                         <span class="n">sync_dist</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

        <span class="n">self</span><span class="p">.</span><span class="n">all_item_embs</span> <span class="o">=</span> <span class="bp">None</span>

    <span class="k">def</span> <span class="nf">validation_epoch_end</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">outputs</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="nf">_val_test_epoch_end</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="sh">"</span><span class="s">val</span><span class="sh">"</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">test_epoch_end</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">outputs</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="nf">_val_test_epoch_end</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="sh">"</span><span class="s">test</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="next-steps-experimenting-with-recommender-systems">Next Steps: Experimenting with Recommender Systems</h2>

<p>After implementing and integrating these evaluation metrics into your PyTorch Lightning model, you can use them to gauge the performance of your recommender system. Additionally, you can employ these metrics to compare different models and decide which one is best suited for your application.</p>]]></content><author><name>Wenhao Deng</name><email>wenhao.deng@foxmail.com</email></author><summary type="html"><![CDATA[To assess the performance of Recommender systems, we need to have reliable evaluation metrics. In this blog post, we will discuss three popular metrics: Hit Rate (HR), Normalized Discounted Cumulative Gain (NDCG), and Mean Reciprocal Rank (MRR). We will also show you how to easily implement these metrics using TorchMetrics and integrate them into a PyTorch Lightning model.]]></summary></entry><entry><title type="html">Limitation of ChatGPT in Causal Inference</title><link href="https://w3nhao.github.io/2023/03/30/Limitation-ChatGPT-Causal-Inference/" rel="alternate" type="text/html" title="Limitation of ChatGPT in Causal Inference" /><published>2023-03-30T00:00:00+01:00</published><updated>2023-03-30T00:00:00+01:00</updated><id>https://w3nhao.github.io/2023/03/30/Limitation-ChatGPT-Causal-Inference</id><content type="html" xml:base="https://w3nhao.github.io/2023/03/30/Limitation-ChatGPT-Causal-Inference/"><![CDATA[<p>In the realm of artificial intelligence, the ability to understand and reason about causality has always been a significant challenge. In a recent exchange on Twitter, Turing Prize Laureate Judea Pearl and AI enthusiast Jim Fan discussed the limitations of GPT, a state-of-the-art language model, in inferring causal relationships.</p>

<div class="l-body">
    <a href="https://twitter.com/yudapearl/status/1641386266595033088">
        <img src="/public/img/2023-03-30-Limitation-ChatGPT-Causal-Inference/tweet_screen_shot_20230331.png" alt="tweet" /> 
    </a>
</div>

<h2 id="judea-pearls-critique">Judea Pearl’s Critique</h2>
<p>According to Judea Pearl, deep learning models like GPT are inherently limited in their ability to reason about causality. He argues that their achievements amount to little more than “curve fitting” and are constrained by the passive data they are trained on. Pearl posits that answering causal questions requires either causal assumptions or interventional experiments to enrich the data.</p>

<h2 id="jim-fans-perspective">Jim Fan’s Perspective</h2>
<p>Jim Fan, on the other hand, highlights GPT’s impressive performance in reasoning about “why” (cause and effect) and “what if” (counterfactual imagination). He suggests that GPT’s ability to infer causality could be attributed to:</p>

<ul>
  <li>The presence of causal examples and counterfactuals in the pre-training data.</li>
  <li>Inductive reasoning based on common sense.</li>
  <li>Language pattern matching.</li>
  <li>Heuristics applied to novel cases.</li>
</ul>

<h2 id="the-inherent-limitations-of-gpt">The Inherent Limitations of GPT</h2>
<p>While GPT demonstrates some ability to reason about causality, it is important to recognize its inherent limitations. As an AI language model, GPT is unable to directly manipulate variables or actively collect new data to validate its causal inferences. Instead, it relies on the causal assumptions and human judgments present in its training data.</p>

<p>One example of this limitation can be seen in a hypothetical scenario where GPT is trained on a dataset containing the false statement: “Jumping from a building won’t kill you because it’s from the tenth floor.” In this case, GPT might take this erroneous story as a causal assumption and generate incorrect inferences when answering related questions. Since GPT lacks the ability to interact with the real world and conduct interventional experiments, it cannot validate or correct its understanding of the causal relationship.</p>

<h2 id="a-cautious-approach-to-causal-inference">A Cautious Approach to Causal Inference</h2>
<p>In light of these limitations, it is essential to exercise caution when using GPT or similar models for causal inference. To obtain more accurate results, it may be necessary to combine GPT’s output with correct causal assumptions or conduct interventional experiments where possible.</p>

<p>In conclusion, the dialogue between Judea Pearl and Jim Fan serves as a valuable reminder of the limitations of deep learning models like GPT in the domain of causal inference. While these models have made significant strides in various aspects of natural language understanding, their abilities in causal reasoning remain constrained by their training data and the algorithms themselves.</p>]]></content><author><name>Wenhao Deng</name><email>wenhao.deng@foxmail.com</email></author><summary type="html"><![CDATA[In the realm of artificial intelligence, the ability to understand and reason about causality has always been a significant challenge. In a recent exchange on Twitter, Turing Prize Laureate Judea Pearl and AI enthusiast Jim Fan discussed the limitations of GPT, a state-of-the-art language model, in inferring causal relationships.]]></summary></entry><entry><title type="html">Falsificationism and Bayesianism</title><link href="https://w3nhao.github.io/2023/03/29/Falsificationism-and-Bayesianism/" rel="alternate" type="text/html" title="Falsificationism and Bayesianism" /><published>2023-03-29T00:00:00+01:00</published><updated>2023-03-29T00:00:00+01:00</updated><id>https://w3nhao.github.io/2023/03/29/Falsificationism-and-Bayesianism</id><content type="html" xml:base="https://w3nhao.github.io/2023/03/29/Falsificationism-and-Bayesianism/"><![CDATA[<p>Philosophy of science is a discipline that studies the nature, methods, categories, and knowledge structure of science. Among them, falsificationism and Bayesianism are two important philosophical views on science, which emphasize different reasoning methods and evidence verification methods.</p>

<h2 id="falsificationism">Falsificationism</h2>

<p>Falsificationism is a philosophical view on science proposed by the philosopher Karl Popper <cite key="1" data-info="Popper, K. R. (1959). The logic of scientific discovery. Routledge."></cite>. Falsificationism holds that scientific theories should be falsifiable, and scientists should try to prove a theory wrong rather than seek evidence to support it. Falsificationism emphasizes the importance of critically testing scientific theories.</p>

<p>However, falsificationism also has some limitations. Firstly, falsificationism tends to emphasize deductive reasoning while neglecting the importance of inductive reasoning in science. Secondly, the simplification of the relationship between theory and observation by falsificationism may lead to misunderstandings. Observational data may be influenced by many factors, and experimental results usually depend on the scientific instruments and technologies used <footnote data-info="For example, the &lt;a href='https://en.wikipedia.org/wiki/Michelson–Morley_experiment'&gt;Michelson-Morley experiment&lt;/a&gt;, which was designed to detect the ether, failed to detect the ether, but it did not falsify the theory of the ether. Instead, it led to the development of the theory of relativity."></footnote>. In addition, falsificationism advocates abandoning a theory when it is sufficiently falsified. However, in practical scientific practice, it is difficult to determine when a theory has been sufficiently falsified. Therefore, the application of falsificationism also needs to consider uncertainty and complexity.</p>

<h2 id="bayesianism">Bayesianism</h2>

<p>Compared to falsificationism, Bayesianism tries to save inductive reasoning and provides another perspective. Bayesianism, based on Bayes’ theorem, quantifies beliefs by calculating probabilities as the basis for reasoning and decision-making. They believe that new evidence updates our beliefs about a proposition or hypothesis, and these beliefs are adjusted according to Bayes’ theorem.</p>

<p>The specific ways in which Bayesianism saves inductive reasoning include using prior probabilities, updating beliefs, and probability reasoning <cite key="2" data-info="Jaynes, E. T. (2003). Probability theory: The logic of science. Cambridge University Press."></cite>. However, Bayesianism also faces some criticisms, such as subjectivity, computational complexity, model selection, and overfitting problems <cite key="3" data-info="Gelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., &amp; Rubin, D. B. (2013). Bayesian data analysis (3rd ed.). Chapman and Hall/CRC."></cite>.</p>

<h2 id="comparison-of-the-two-views">Comparison of the Two Views</h2>

<p>Falsificationism and Bayesianism are two different philosophical views on science, which emphasize different reasoning methods and evidence verification methods. Compared to falsificationism, Bayesianism pays more attention to uncertainty and complexity and tries to handle these problems through quantifying beliefs and probability calculations.</p>

<p>The comparison of the two views can be carried out from the following aspects:</p>

<h3 id="reasoning-methods">Reasoning Methods</h3>

<p>Falsificationism emphasizes deductive reasoning, that is, deriving specific conclusions from general principles, and emphasizes finding counterexamples from observational data to prove a theory wrong. Bayesianism is more concerned with inductive reasoning, that is, deriving general principles from specific situations and updating beliefs based on new evidence.</p>

<h3 id="evidence-verification">Evidence Verification</h3>

<p>Falsificationism holds that a theory should only be abandoned when it is sufficiently falsified by evidence. Bayesianism holds that any new evidence should be used to update prior beliefs and adjust posterior beliefs according to Bayes’ theorem.</p>

<h3 id="handling-uncertainty">Handling Uncertainty</h3>

<p>Falsificationism handles uncertainty relatively simply, that is, falsifying a theory based on observational data. Bayesianism pays more attention to quantifying uncertainty and tries to handle uncertainty and complexity problems through probability calculations.</p>

<h3 id="limitations">Limitations</h3>

<p>The limitations of falsificationism include neglecting the role of inductive reasoning in science and the problem of the relationship between theory and observation. The limitations of Bayesianism include subjectivity, computational complexity, model selection, and overfitting problems.</p>

<h2 id="conclusion">Conclusion</h2>

<p>Falsificationism and Bayesianism are two different philosophical views on science, which emphasize different reasoning methods and evidence verification methods. Although falsificationism has some limitations, it emphasizes the importance of critically testing scientific theories and is an important part of the philosophy of science. Bayesianism pays more attention to uncertainty and complexity and tries to handle these problems through quantifying beliefs and probability calculations, which has broad application value in practical use.</p>]]></content><author><name>Wenhao Deng</name><email>wenhao.deng@foxmail.com</email></author><summary type="html"><![CDATA[Philosophy of science is a discipline that studies the nature, methods, categories, and knowledge structure of science. Among them, falsificationism and Bayesianism are two important philosophical views on science, which emphasize different reasoning methods and evidence verification methods.]]></summary></entry></feed>