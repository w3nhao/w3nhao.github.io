<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      Blog Posts · Wenhao Deng
    
  </title>

  
  <link rel="canonical" href="http://localhost:4000/posts/">
  

  <link rel="stylesheet" href="http://localhost:4000/public/css/poole.css">
  <link rel="stylesheet" href="http://localhost:4000/public/css/syntax.css">
  <link rel="stylesheet" href="http://localhost:4000/public/css/lanyon.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700%7CPT+Sans:400">

  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="http://localhost:4000/public/apple-touch-icon-precomposed.png">
  <link rel="shortcut icon" href="http://localhost:4000/public/favicon.ico">

  <link rel="alternate" type="application/rss+xml" title="RSS" href="http://localhost:4000/atom.xml">

  

  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.0/css/all.min.css" crossorigin="anonymous">

  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']],
        processEscapes: true,
        processEnvironments: true
      },
      options: {
        skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
      }
    };
  </script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  
  
<script>MathJax={"tex":{"inlineMath":[["$","$"],["\\(","\\)"]],"displayMath":[["$$","$$"],["\\[","\\]"]]},"svg":{"fontCache":"global"}}</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>



  <body>

    <!-- Target for toggling the sidebar `.sidebar-checkbox` is for regular
     styles, `#sidebar-checkbox` for behavior. -->
<input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox">

<!-- Toggleable sidebar -->
<div class="sidebar" id="sidebar">
  <div class="sidebar-item">
    <p></p>
  </div>

  <nav class="sidebar-nav">
    <a class="sidebar-nav-item" href="http://localhost:4000/">Home</a>

    

    
    
      
        
      
    
      
        
      
    
      
    
      
    
      
        
          <a class="sidebar-nav-item active" href="http://localhost:4000/posts/">Blog Posts</a>
        
      
    
      
    
      
    

    <!-- <a class="sidebar-nav-item" href="/archive/v1.1.0.zip">Download</a> -->
    <!-- <a class="sidebar-nav-item" href="">GitHub project</a> -->
    <!-- <span class="sidebar-nav-item">Currently v1.1.0</span> -->
  </nav>

  <div class="sidebar-item">
    <p>
      © 2023. All rights reserved.
    </p>
  </div>
</div>


    <!-- Wrap is the content to shift when toggling the sidebar. We wrap the
         content to avoid any CSS collisions with our real content. -->
    <div class="wrap">
      <div class="masthead">
        <div class="container">
          <h3 class="masthead-title">
            <a href="/" title="Home">Wenhao Deng</a>
            <small></small>
          </h3>
        </div>
      </div>

      <div class="container content">
        <div class="page">
  <h1 class="page-title">Blog Posts</h1>
  <div class="posts">
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://localhost:4000/2023/03/31/HR-MRR-NDCG-Torchmetric-Implementation/">
        HR, NDCG, and MRR: An easy implementation with TorchMetrics
      </a>
    </h1>

    <span class="post-date">31 Mar 2023</span>

    <p>To assess the performance of  Recommender systems, we need to have reliable evaluation metrics. In this blog post, we will discuss three popular metrics: Hit Rate (HR), Normalized Discounted Cumulative Gain (NDCG), and Mean Reciprocal Rank (MRR). We will also show you how to easily implement these metrics using TorchMetrics and integrate them into a PyTorch Lightning model.</p>

<h2 id="0-understanding-the-get_topk_ranks-function">0. Understanding the <code class="language-plaintext highlighter-rouge">get_topk_ranks</code> Function</h2>

<p>In the context of our recommender system evaluation, it is essential to understand the <code class="language-plaintext highlighter-rouge">get_topk_ranks</code> function, which plays a crucial role in computing the ranks of the target items in the predicted scores. This function is used as an intermediate step to calculate the HR, NDCG, and MRR metrics.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">get_topk_ranks</span><span class="p">(</span><span class="n">pred_scores</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">topk</span><span class="p">):</span>
    <span class="s">""" get topk ranks of the target in the pred_scores
    Args:
        pred_scores: (batch_size, item_num(with padding item))
        target: (batch_size, ) or (batch_size, 1)
        topk: int
        
    Returns:
        topk_rank: (batch_size, 1) topk + 1 if not hit, 1 is the first rank
    """</span>
    <span class="k">assert</span> <span class="n">target</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">pred_scores</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">assert</span> <span class="n">pred_scores</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">topk</span>
    <span class="n">target</span> <span class="o">=</span> <span class="n">target</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="n">target</span><span class="p">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">target</span>

    <span class="n">_</span><span class="p">,</span> <span class="n">topk_idx</span> <span class="o">=</span> <span class="n">pred_scores</span><span class="p">.</span><span class="nf">topk</span><span class="p">(</span><span class="n">topk</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">hitted_row</span><span class="p">,</span> <span class="n">rank</span> <span class="o">=</span> <span class="p">(</span><span class="n">target</span> <span class="o">==</span> <span class="n">topk_idx</span><span class="p">).</span><span class="nf">nonzero</span><span class="p">().</span><span class="nf">split</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">rank</span> <span class="o">+=</span> <span class="mi">1</span>
    
    <span class="c1"># first set all rank to maximum value 
</span>    <span class="c1"># int64 or set all rank to topk + 1
</span>    <span class="n">all_rank</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">full_like</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">topk</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="c1"># then set the hitted row to the rank
</span>    <span class="n">all_rank</span> <span class="o">=</span> <span class="n">all_rank</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">hitted_row</span><span class="p">,</span> <span class="n">rank</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">all_rank</span>
</code></pre></div></div>

<h3 id="the-get_topk_ranks-function-explained">The <code class="language-plaintext highlighter-rouge">get_topk_ranks</code> Function Explained</h3>

<p>The <code class="language-plaintext highlighter-rouge">get_topk_ranks</code> function takes three arguments: <code class="language-plaintext highlighter-rouge">pred_scores</code>, <code class="language-plaintext highlighter-rouge">target</code>, and <code class="language-plaintext highlighter-rouge">topk</code>. It returns the ranks of the target items within the top-k predictions.</p>

<ol>
  <li>
    <p><code class="language-plaintext highlighter-rouge">pred_scores</code>: A tensor of shape <code class="language-plaintext highlighter-rouge">(batch_size, item_num(with padding item))</code>, representing the predicted scores for each item for all users in a batch.</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">target</code>: A tensor of shape <code class="language-plaintext highlighter-rouge">(batch_size,)</code> or <code class="language-plaintext highlighter-rouge">(batch_size, 1)</code>, containing the ground truth target items for each user in the batch.</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">topk</code>: An integer value representing the number of top items we want to consider.</p>
  </li>
</ol>

<p>The function returns a tensor <code class="language-plaintext highlighter-rouge">topk_rank</code> of shape <code class="language-plaintext highlighter-rouge">(batch_size, 1)</code> containing the top-k ranks of the target items in the predicted scores. If a target item is not in the top-k predictions, the rank will be set to <code class="language-plaintext highlighter-rouge">topk + 1</code>.</p>

<h3 id="how-the-get_topk_ranks-function-works">How the <code class="language-plaintext highlighter-rouge">get_topk_ranks</code> Function Works</h3>

<p>The <code class="language-plaintext highlighter-rouge">get_topk_ranks</code> function follows these steps to compute the ranks:</p>

<ol>
  <li>
    <p>Ensures that the target tensor has two dimensions by unsqueezing it if necessary.</p>
  </li>
  <li>
    <p>Retrieves the indices of the top-k items in the predicted scores using the <code class="language-plaintext highlighter-rouge">topk()</code> method.</p>
  </li>
  <li>
    <p>Computes the ranks of the target items within the top-k predictions by checking if the target item is present in the top-k indices.</p>
  </li>
  <li>
    <p>Initializes a tensor <code class="language-plaintext highlighter-rouge">all_rank</code> with the same shape as the target tensor, filled with the value <code class="language-plaintext highlighter-rouge">topk + 1</code>.</p>
  </li>
  <li>
    <p>Updates the <code class="language-plaintext highlighter-rouge">all_rank</code> tensor with the computed ranks for each user using the <code class="language-plaintext highlighter-rouge">scatter()</code> method.</p>
  </li>
</ol>

<p>By using the <code class="language-plaintext highlighter-rouge">get_topk_ranks</code> function, we can efficiently compute the top-k ranks for each user in a batch, which is an essential step for calculating HR, NDCG, and MRR metrics in our recommender system evaluation.</p>

<h2 id="1-hit-rate-hr">1. Hit Rate (HR)</h2>

<p>Hit Rate is a simple and intuitive metric that measures the proportion of relevant items recommended to the user.</p>

<p><strong>Mathematical Definition:</strong></p>

<p>HR@k = (Number of hits in the top-k recommendations) / (Total number of recommendations)</p>

<p>The Hit Ratio (HR) is a binary metric that measures whether a relevant item is present in the top-k recommendations or not. Mathematically, it can be expressed as:</p>

<p>$$\text{HR@k} = \frac{1}{|U|}\sum_{u=1}^{|U|} \text{hit}_u
$$</p>

<p>
where $|U|$ is the number of users, and $\text{hit}_u$ is 1 if the ground truth item is present in the top-k recommendations for user $u$, and 0 otherwise.
</p>

<p><strong>TorchMetrics Implementation:</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">torchmetrics</span> <span class="kn">import</span> <span class="n">Metric</span>

<span class="k">class</span> <span class="nc">HR</span><span class="p">(</span><span class="n">Metric</span><span class="p">):</span>
    <span class="p">...</span>
    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">topk_rank</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">accumulate_count</span> <span class="o">+=</span> <span class="n">topk_rank</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">self</span><span class="p">.</span><span class="n">accumulate_metric</span> <span class="o">+=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_metric</span><span class="p">(</span><span class="n">topk_rank</span><span class="p">[</span><span class="n">topk_rank</span> <span class="o">&lt;=</span> <span class="n">self</span><span class="p">.</span><span class="n">k</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">_metric</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">topk_rank</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">topk_rank</span><span class="p">.</span><span class="nf">numel</span><span class="p">()</span>
</code></pre></div></div>

<h2 id="2-normalized-discounted-cumulative-gain-ndcg">2. Normalized Discounted Cumulative Gain (NDCG)</h2>
<p>NDCG is a metric that measures the quality of the ranking of the recommended items, taking into account their relevance and position in the list.</p>

<p><strong>Mathematical Definition:</strong></p>

<p>Normalized Discounted Cumulative Gain (NDCG) is a measure that evaluates the quality of the ranking of recommended items. It takes into account the positions of relevant items in the top-k recommendations. The NDCG@k is defined as:</p>

<p>NDCG@k = (DCG@k) / (IDCG@k)</p>

<p>where DCG@k is the Discounted Cumulative Gain at position k, and IDCG@k is the Ideal Discounted Cumulative Gain at position k.</p>

<p>DCG@k = sum(relevance_i / log2(i + 1)) for i in range(1, k + 1)</p>

<p>$$\text{NDCG@k} = \frac{1}{|U|} \sum_{u=1}^{|U|} \frac{\sum_{i=1}^{k} \frac{2^{\text{rel}_i(u)} - 1}{\log_2{(i+1)}}}{\text{IDCG}_u}
$$</p>

<p>
where $|U|$ is the number of users, $\text{rel}_i(u)$ is the relevance score of item $i$ for user $u$, and $\text{IDCG}_u$ is the Ideal Discounted Cumulative Gain for user $u$, which is the maximum possible NDCG for that user.
</p>

<p><strong>TorchMetrics Implementation:</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">torchmetrics</span> <span class="kn">import</span> <span class="n">Metric</span>

<span class="k">class</span> <span class="nc">NDCG</span><span class="p">(</span><span class="n">Metric</span><span class="p">):</span>
    <span class="p">...</span>
    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">topk_rank</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">accumulate_count</span> <span class="o">+=</span> <span class="n">topk_rank</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">self</span><span class="p">.</span><span class="n">accumulate_metric</span> <span class="o">+=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_metric</span><span class="p">(</span><span class="n">topk_rank</span><span class="p">[</span><span class="n">topk_rank</span> <span class="o">&lt;=</span> <span class="n">self</span><span class="p">.</span><span class="n">k</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">_metric</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">topk_rank</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">torch</span><span class="p">.</span><span class="nf">log2</span><span class="p">(</span><span class="n">topk_rank</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
</code></pre></div></div>

<h2 id="3-mean-reciprocal-rank-mrr">3. Mean Reciprocal Rank (MRR)</h2>
<p>MRR is a metric that measures the quality of the ranking of the recommended items by computing the average of the reciprocal ranks of the first relevant item in the list.</p>

<p><strong>Mathematical Definition:</strong></p>

<p>Mean Reciprocal Rank (MRR) is another metric that evaluates the ranking quality of recommended items. It is the average of the reciprocal of the rank of the first relevant item in the top-k recommendations for each user. MRR can be defined as:</p>

<p>MRR@k = (1 / Number of users) * sum(1 / rank_i) for i in range(Number of users)</p>

<p>$$\text{MRR@k} = \frac{1}{|U|}\sum_{u=1}^{|U|} \frac{1}{\text{rank}_u}
$$</p>

<p>
where $|U|$ is the number of users, and $\text{rank}_u$ is the position of the first relevant item in the top-k recommendations for user $u$.
</p>

<p><strong>TorchMetrics Implementation:</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">torchmetrics</span> <span class="kn">import</span> <span class="n">Metric</span>

<span class="k">class</span> <span class="nc">MRR</span><span class="p">(</span><span class="n">Metric</span><span class="p">):</span>
    <span class="p">...</span>
    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">topk_rank</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">accumulate_count</span> <span class="o">+=</span> <span class="n">topk_rank</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">self</span><span class="p">.</span><span class="n">accumulate_metric</span> <span class="o">+=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_metric</span><span class="p">(</span><span class="n">topk_rank</span><span class="p">[</span><span class="n">topk_rank</span> <span class="o">&lt;=</span> <span class="n">self</span><span class="p">.</span><span class="n">k</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">_metric</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">topk_rank</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">topk_rank</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="integrating-metrics-with-pytorch-lightning">Integrating Metrics with PyTorch Lightning</h2>
<p>Now, let’s demonstrate how to integrate these evaluation metrics into a PyTorch Lightning model using a sample recommender system called SASRec.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pytorch_lightning</span> <span class="k">as</span> <span class="n">pl</span>
<span class="kn">from</span> <span class="n">torchmetrics</span> <span class="kn">import</span> <span class="n">MetricCollection</span>

<span class="k">class</span> <span class="nc">SASRec</span><span class="p">(</span><span class="n">pl</span><span class="p">.</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="p">...):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="p">...</span>
        <span class="n">self</span><span class="p">.</span><span class="n">topk_list</span> <span class="o">=</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">]</span>
        <span class="n">self</span><span class="p">.</span><span class="n">topk_metric</span> <span class="o">=</span> <span class="n">MetricCollection</span>
        <span class="p">({</span>
            <span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">metric_name</span><span class="si">}</span><span class="s">@</span><span class="si">{</span><span class="n">topk</span><span class="si">}</span><span class="s">"</span><span class="p">:</span> <span class="nf">globals</span><span class="p">()[</span><span class="n">metric_name</span><span class="p">](</span><span class="n">topk</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">metric_name</span> <span class="ow">in</span> <span class="p">[</span><span class="s">"HR"</span><span class="p">,</span> <span class="s">"NDCG"</span><span class="p">,</span> <span class="s">"MRR"</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">topk</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">topk_list</span>
        <span class="p">})</span>

    <span class="k">def</span> <span class="nf">_on_val_test_epoch_start</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">topk</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">topk_list</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">metric_name</span> <span class="ow">in</span> <span class="n">METRIC_LIST</span><span class="p">:</span>
                <span class="n">self</span><span class="p">.</span><span class="n">topk_metric</span><span class="p">[</span><span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">metric_name</span><span class="si">}</span><span class="s">@</span><span class="si">{</span><span class="n">topk</span><span class="si">}</span><span class="s">"</span><span class="p">].</span><span class="nf">reset</span><span class="p">()</span>

        <span class="n">self</span><span class="p">.</span><span class="nf">register_buffer</span><span class="p">(</span>
            <span class="s">"all_item_embs"</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="nf">item_encoder</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">all_item_ids</span><span class="p">),</span> <span class="n">persistent</span><span class="o">=</span><span class="bp">False</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">on_validation_epoch_start</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="nf">_on_val_test_epoch_start</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">on_test_epoch_start</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="nf">_on_val_test_epoch_start</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_val_test_step</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">stage</span><span class="p">):</span>
        <span class="p">...</span>

        <span class="n">pred_item_embs</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">forward</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">input_mask</span><span class="p">)</span>
        <span class="n">pred_scores</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">matmul</span><span class="p">(</span><span class="n">pred_item_embs</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">all_item_embs</span><span class="p">.</span><span class="nf">t</span><span class="p">()).</span><span class="nf">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">pred_scores</span> <span class="o">=</span> <span class="n">pred_scores</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">history</span><span class="p">,</span> <span class="o">-</span><span class="nf">float</span><span class="p">(</span><span class="s">'inf'</span><span class="p">))</span>

        <span class="n">target</span> <span class="o">=</span> <span class="n">behavs</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">target</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">topk</span> <span class="o">=</span> <span class="nf">max</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">topk_list</span><span class="p">)</span>
        <span class="n">all_ranks</span> <span class="o">=</span> <span class="nf">get_topk_ranks</span><span class="p">(</span><span class="n">pred_scores</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">topk</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">topk</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">topk_list</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">metric_name</span> <span class="ow">in</span> <span class="n">METRIC_LIST</span><span class="p">:</span>
                <span class="n">metric</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">topk_metric</span><span class="p">[</span><span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">metric_name</span><span class="si">}</span><span class="s">@</span><span class="si">{</span><span class="n">topk</span><span class="si">}</span><span class="s">"</span><span class="p">]</span>
                <span class="n">metric</span><span class="p">.</span><span class="nf">update</span><span class="p">(</span><span class="n">all_ranks</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">validation_step</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="nf">_val_test_step</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="s">"val"</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="nf">_val_test_step</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="s">"test"</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_val_test_epoch_end</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">stage</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">topk</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">topk_list</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">metric_name</span> <span class="ow">in</span> <span class="n">METRIC_LIST</span><span class="p">:</span>
                <span class="n">score</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">topk_metric</span><span class="p">[</span><span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">metric_name</span><span class="si">}</span><span class="s">@</span><span class="si">{</span><span class="n">topk</span><span class="si">}</span><span class="s">"</span><span class="p">].</span><span class="nf">compute</span><span class="p">()</span>
                <span class="k">if</span> <span class="n">metric_name</span> <span class="ow">in</span> <span class="p">[</span><span class="s">"HR"</span><span class="p">,</span> <span class="s">"NDCG"</span><span class="p">]</span> <span class="ow">and</span> <span class="n">topk</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">]:</span>
                    <span class="n">log_on_progress_bar</span> <span class="o">=</span> <span class="bp">True</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">log_on_progress_bar</span> <span class="o">=</span> <span class="bp">False</span>
                <span class="n">self</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">stage</span><span class="si">}</span><span class="s">_</span><span class="si">{</span><span class="n">metric_name</span><span class="si">}</span><span class="s">@</span><span class="si">{</span><span class="n">topk</span><span class="si">}</span><span class="s">"</span><span class="p">,</span>
                         <span class="n">score</span><span class="p">,</span>
                         <span class="n">on_epoch</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                         <span class="n">prog_bar</span><span class="o">=</span><span class="n">log_on_progress_bar</span><span class="p">,</span>
                         <span class="n">logger</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                         <span class="n">sync_dist</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

        <span class="n">self</span><span class="p">.</span><span class="n">all_item_embs</span> <span class="o">=</span> <span class="bp">None</span>

    <span class="k">def</span> <span class="nf">validation_epoch_end</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">outputs</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="nf">_val_test_epoch_end</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="s">"val"</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">test_epoch_end</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">outputs</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="nf">_val_test_epoch_end</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="s">"test"</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="next-steps-experimenting-with-recommender-systems">Next Steps: Experimenting with Recommender Systems</h2>

<p>After implementing and integrating these evaluation metrics into your PyTorch Lightning model, you can use them to gauge the performance of your recommender system. Additionally, you can employ these metrics to compare different models and decide which one is best suited for your application.</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://localhost:4000/2023/03/30/Limitation-ChatGPT-Causal-Inference/">
        Limitation of ChatGPT in Causal Inference
      </a>
    </h1>

    <span class="post-date">30 Mar 2023</span>

    <p>In the realm of artificial intelligence, the ability to understand and reason about causality has always been a significant challenge. In a recent exchange on Twitter, Turing Prize Laureate Judea Pearl and AI enthusiast Jim Fan discussed the limitations of GPT, a state-of-the-art language model, in inferring causal relationships.</p>

<p><img src="%5C../public/img/tweet_screen_shot_20230331.png#pic_center#%20=200x200" alt="img">
<a href="https://twitter.com/yudapearl/status/1641386266595033088">tweet_link</a></p>

<h2 id="judea-pearls-critique">Judea Pearl’s Critique</h2>
<p>According to Judea Pearl, deep learning models like GPT are inherently limited in their ability to reason about causality. He argues that their achievements amount to little more than “curve fitting” and are constrained by the passive data they are trained on. Pearl posits that answering causal questions requires either causal assumptions or interventional experiments to enrich the data.</p>

<h2 id="jim-fans-perspective">Jim Fan’s Perspective</h2>
<p>Jim Fan, on the other hand, highlights GPT’s impressive performance in reasoning about “why” (cause and effect) and “what if” (counterfactual imagination). He suggests that GPT’s ability to infer causality could be attributed to:</p>

<ul>
  <li>The presence of causal examples and counterfactuals in the pre-training data.</li>
  <li>Inductive reasoning based on common sense.</li>
  <li>Language pattern matching.</li>
  <li>Heuristics applied to novel cases.</li>
</ul>

<h2 id="the-inherent-limitations-of-gpt">The Inherent Limitations of GPT</h2>
<p>While GPT demonstrates some ability to reason about causality, it is important to recognize its inherent limitations. As an AI language model, GPT is unable to directly manipulate variables or actively collect new data to validate its causal inferences. Instead, it relies on the causal assumptions and human judgments present in its training data.</p>

<p>One example of this limitation can be seen in a hypothetical scenario where GPT is trained on a dataset containing the false statement: “Jumping from a building won’t kill you because it’s from the tenth floor.” In this case, GPT might take this erroneous story as a causal assumption and generate incorrect inferences when answering related questions. Since GPT lacks the ability to interact with the real world and conduct interventional experiments, it cannot validate or correct its understanding of the causal relationship.</p>

<h2 id="a-cautious-approach-to-causal-inference">A Cautious Approach to Causal Inference</h2>
<p>In light of these limitations, it is essential to exercise caution when using GPT or similar models for causal inference. To obtain more accurate results, it may be necessary to combine GPT’s output with correct causal assumptions or conduct interventional experiments where possible.</p>

<p>In conclusion, the dialogue between Judea Pearl and Jim Fan serves as a valuable reminder of the limitations of deep learning models like GPT in the domain of causal inference. While these models have made significant strides in various aspects of natural language understanding, their abilities in causal reasoning remain constrained by their training data and the algorithms themselves.</p>

<hr>

<font color="LightSlateGray" size="5" face="Times">GPT在因果推理方面的局限性：Judea Pearl和Jim Fan的对话</font>

<p>在人工智能领域，理解和推理因果关系一直是一个重要的挑战。最近，在Twitter上，图灵奖得主Judea Pearl和人工智能爱好者Jim Fan就GPT这一最先进的语言模型在推断因果关系方面的局限性进行了讨论。</p>

<p>Judea Pearl的批评</p>

<p>据Judea Pearl称，像GPT这样的深度学习模型在推理因果关系方面存在内在的局限性。他认为，这些模型的成就只不过是“曲线拟合”，并受到它们所训练的被动数据的限制。Pearl认为，回答因果问题需要因果假设或干预实验来丰富数据。</p>

<p>Jim Fan的观点</p>

<p>另一方面，Jim Fan强调了GPT在推理“为什么”（因果关系）和“如果”（反事实想象）方面的卓越表现。他认为，GPT推断因果关系的能力可以归因于：</p>

<ul>
  <li>预训练数据中存在因果示例和反事实条件。</li>
  <li>基于常识的归纳推理。</li>
  <li>语言模式匹配。</li>
  <li>应用于新情况的启发式方法。</li>
</ul>

<p>GPT的内在局限性</p>

<p>尽管GPT在因果推理方面表现出一定的能力，但我们仍需认识到其内在的局限性。作为一种人工智能语言模型，GPT无法直接操纵变量或主动收集新数据以验证其因果推断。相反，它依赖于训练数据中的因果假设和人类判断。</p>

<p>这种局限性的一个例子是，在一个假设的场景中，GPT接受了一个包含错误陈述的数据集：“跳楼不会死，因为跳的是十楼。” 在这种情况下，GPT可能会将这个错误的故事作为因果假设，并在回答相关问题时产生错误的推断。由于GPT缺乏与现实世界互动和进行干预实验的能力，它无法验证或纠正其对因果关系的理解。</p>

<p>小心谨慎地进行因果推理</p>

<p>鉴于这些局限性，在使用GPT或类似模型进行因果推理时，必须小心谨慎。为了获得更准确的结果，可能需要将GPT的输出与正确的因果假设相结合，或在可能的情况下进行干预实验。</p>

<p>总之，Judea Pearl和Jim Fan之间的对话为我们提醒了深度学习模型如GPT在因果推理领域的局限性。虽然这些模型在自然语言理解的各个方面取得了重要进展，但它们在因果推理能力方面仍受到训练数据和算法本身的限制。</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://localhost:4000/2023/03/29/Falsificationism-and-Bayesianism/">
        Falsificationism and Bayesianism
      </a>
    </h1>

    <span class="post-date">29 Mar 2023</span>

    <!-- English Content Start -->

<p>Philosophy of science is a discipline that studies the nature, methods, categories, and knowledge structure of science. Among them, falsificationism and Bayesianism are two important philosophical views on science, which emphasize different reasoning methods and evidence verification methods.</p>

<h2 id="falsificationism">Falsificationism</h2>

<p>Falsificationism is a philosophical view on science proposed by the philosopher Karl Popper [1]. Falsificationism holds that scientific theories should be falsifiable, and scientists should try to prove a theory wrong rather than seek evidence to support it. Falsificationism emphasizes the importance of critically testing scientific theories.</p>

<p>However, falsificationism also has some limitations. Firstly, falsificationism tends to emphasize deductive reasoning while neglecting the importance of inductive reasoning in science. Secondly, the simplification of the relationship between theory and observation by falsificationism may lead to misunderstandings. Observational data may be influenced by many factors, and experimental results usually depend on the scientific instruments and technologies used. In addition, falsificationism advocates abandoning a theory when it is sufficiently falsified. However, in practical scientific practice, it is difficult to determine when a theory has been sufficiently falsified. Therefore, the application of falsificationism also needs to consider uncertainty and complexity.</p>

<h2 id="bayesianism">Bayesianism</h2>

<p>Compared to falsificationism, Bayesianism tries to save inductive reasoning and provides another perspective. Bayesianism, based on Bayes’ theorem, quantifies beliefs by calculating probabilities as the basis for reasoning and decision-making. They believe that new evidence updates our beliefs about a proposition or hypothesis, and these beliefs are adjusted according to Bayes’ theorem.</p>

<p>The specific ways in which Bayesianism saves inductive reasoning include using prior probabilities, updating beliefs, and probability reasoning [2]. However, Bayesianism also faces some criticisms, such as subjectivity, computational complexity, model selection, and overfitting problems [3].</p>

<h2 id="comparison-of-the-two-views">Comparison of the Two Views</h2>

<p>Falsificationism and Bayesianism are two different philosophical views on science, which emphasize different reasoning methods and evidence verification methods. Compared to falsificationism, Bayesianism pays more attention to uncertainty and complexity and tries to handle these problems through quantifying beliefs and probability calculations.</p>

<p>The comparison of the two views can be carried out from the following aspects:</p>

<h3 id="reasoning-methods">Reasoning Methods</h3>

<p>Falsificationism emphasizes deductive reasoning, that is, deriving specific conclusions from general principles, and emphasizes finding counterexamples from observational data to prove a theory wrong. Bayesianism is more concerned with inductive reasoning, that is, deriving general principles from specific situations and updating beliefs based on new evidence.</p>

<h3 id="evidence-verification">Evidence Verification</h3>

<p>Falsificationism holds that a theory should only be abandoned when it is sufficiently falsified by evidence. Bayesianism holds that any new evidence should be used to update prior beliefs and adjust posterior beliefs according to Bayes’ theorem.</p>

<h3 id="handling-uncertainty">Handling Uncertainty</h3>

<p>Falsificationism handles uncertainty relatively simply, that is, falsifying a theory based on observational data. Bayesianism pays more attention to quantifying uncertainty and tries to handle uncertainty and complexity problems through probability calculations.</p>

<h3 id="limitations">Limitations</h3>

<p>The limitations of falsificationism include neglecting the role of inductive reasoning in science and the problem of the relationship between theory and observation. The limitations of Bayesianism include subjectivity, computational complexity, model selection, and overfitting problems.</p>

<h1 id="conclusion">Conclusion</h1>

<p>Falsificationism and Bayesianism are two different philosophical views on science, which emphasize different reasoning methods and evidence verification methods. Although falsificationism has some limitations, it emphasizes the importance of critically testing scientific theories and is an important part of the philosophy of science. Bayesianism pays more attention to uncertainty and complexity and tries to handle these problems through quantifying beliefs and probability calculations, which has broad application value in practical use.</p>

<h1 id="references">References</h1>
<p>[1] Popper, K. R. (1959). The logic of scientific discovery. Routledge.</p>

<p>[2] Jaynes, E. T. (2003). Probability theory: The logic of science. Cambridge University Press.</p>

<p>[3] Gelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., &amp; Rubin, D. B. (2013). Bayesian data analysis (3rd ed.). Chapman and Hall/CRC.</p>

<!-- English Content End -->
<!-- Chinese Content Start -->

<hr>

<font color="LightSlateGray" size="5" face="Times">证伪主义与贝叶斯主义：科学哲学的两种观点</font>

<p>科学哲学是研究科学本质、方法、范畴和知识结构的哲学学科。其中，证伪主义和贝叶斯主义是两种重要的科学哲学观点，它们分别强调了不同的推理方式和证据检验方法。</p>

<p>证伪主义</p>

<p>证伪主义是由哲学家卡尔·波普尔提出的一种科学哲学观点。证伪主义认为科学理论应该是可证伪的，而科学家应该尝试证明一个理论是错误的，而不是寻找支持这个理论的证据。证伪主义强调了对科学理论进行批判性检验的重要性。</p>

<p>然而，证伪主义也存在一些局限性。首先，证伪主义倾向于强调演绎推理，而忽略了归纳推理在科学中的重要性。其次，证伪主义对于理论与观察之间关系的简化可能会导致误解。观察数据可能受到许多因素的影响，而且实验结果通常依赖于所使用的科学仪器和技术。此外，证伪主义提倡在理论受到足够证伪证据的情况下舍弃它。然而，在实际科学实践中，很难确定一个理论何时已经被充分证伪。因此，证伪主义的应用也需要考虑不确定性和复杂性。</p>

<p>贝叶斯主义</p>

<p>相对于证伪主义，贝叶斯主义者尝试挽救归纳主义，提供了另一种观点。贝叶斯主义者基于贝叶斯定理，通过计算概率来量化信念，以此作为推理和决策的基础。他们认为，新的证据会更新我们对某一命题或假设的信念，并根据贝叶斯定理调整这些信念。</p>

<p>贝叶斯主义者挽救归纳主义的具体方式包括使用先验概率、更新信念、概率论证等。然而，贝叶斯主义也面临一些批评，如主观性问题、计算复杂性、模型选择和过拟合问题等。</p>

<p>两种观点的比较</p>

<p>证伪主义和贝叶斯主义是两种不同的科学哲学观点，它们分别强调了不同的推理方式和证据检验方法。相对于证伪主义，贝叶斯主义更加注重不确定性和复杂性，并试图通过量化信念和概率计算来处理这些问题。</p>

<p>两种观点的比较可以从以下几个方面进行：</p>

<p>推理方式</p>

<p>证伪主义强调演绎推理，即从一般原则推导出特定结论，强调从观察数据中寻找反例来证明一个理论是错误的。而贝叶斯主义则更注重归纳推理，即从特定情况推导出一般原则，并根据新证据来更新信念。</p>

<p>证据检验</p>

<p>证伪主义认为，一个理论只有在受到充分证伪证据时才应该被舍弃。而贝叶斯主义认为，任何新证据都应该被用来更新先验信念，并根据贝叶斯定理来调整后验信念。</p>

<p>处理不确定性</p>

<p>证伪主义对于不确定性的处理较为简单，即通过观察数据来证伪一个理论。而贝叶斯主义则更注重量化不确定性，并试图通过概率计算来处理不确定性和复杂性问题。</p>

<p>局限性</p>

<p>证伪主义的局限性包括忽略了归纳推理在科学中的作用，以及理论与观察之间的关系问题等。贝叶斯主义的局限性则包括主观性问题、计算复杂性、模型选择和过拟合问题等。</p>

<p>总结</p>

<p>证伪主义和贝叶斯主义是两种不同的科学哲学观点，它们分别强调了不同的推理方式和证据检验方法。虽然证伪主义存在一些局限性，但它强调了对科学理论进行批判性检验的重要性，是科学哲学中的一个重要组成部分。贝叶斯主义则更注重不确定性和复杂性，并试图通过量化信念和概率计算来处理这些问题，在实际应用中具有广泛的应用价值。</p>

  </div>
  
</div>

<div class="pagination">
  
    <span class="pagination-item older">Older</span>
  
  
    <span class="pagination-item newer">Newer</span>
  
</div>
</div>


      </div>
    </div>

    <label for="sidebar-checkbox" class="sidebar-toggle"></label>

    <script src="/public/js/script.js"></script>
  </body>
</html>
