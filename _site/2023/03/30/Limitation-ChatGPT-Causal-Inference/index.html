<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      Limitation of ChatGPT in Causal Inference ¬∑ Wenhao Deng
    
  </title>

  
  <link rel="canonical" href="https://w3nhao.github.io//2023/03/30/Limitation-ChatGPT-Causal-Inference/">
  

  <link rel="stylesheet" href="https://w3nhao.github.io//public/css/poole.css">
  <link rel="stylesheet" href="https://w3nhao.github.io//public/css/syntax.css">
  <link rel="stylesheet" href="https://w3nhao.github.io//public/css/lanyon.css">
  <link rel="stylesheet" href="https://w3nhao.github.io//public/css/dark-mode.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700%7CPT+Sans:400">

  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="https://w3nhao.github.io//public/apple-touch-icon-precomposed.png">
  <link rel="shortcut icon" href="https://w3nhao.github.io//public/favicon.ico">

  <link rel="alternate" type="application/rss+xml" title="RSS" href="https://w3nhao.github.io//atom.xml">

  

  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.0/css/all.min.css" crossorigin="anonymous">

  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']],
        processEscapes: true,
        processEnvironments: true
      },
      options: {
        skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
      }
    };
  </script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  
</head>



  <body>

    <!-- Target for toggling the sidebar `.sidebar-checkbox` is for regular
     styles, `#sidebar-checkbox` for behavior. -->
<input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox">

<!-- Toggleable sidebar -->
<div class="sidebar" id="sidebar">
  <div class="sidebar-item">
    <p></p>
  </div>

  <nav class="sidebar-nav">
    <a class="sidebar-nav-item" href="https://w3nhao.github.io//">Home</a>

    

    
    
      
        
      
    
      
        
      
    
      
    
      
    
      
        
          <a class="sidebar-nav-item" href="https://w3nhao.github.io//posts/">Blog Posts</a>
        
      
    
      
    
      
    

    <!-- <a class="sidebar-nav-item" href="/archive/v1.1.0.zip">Download</a> -->
    <!-- <a class="sidebar-nav-item" href="">GitHub project</a> -->
    <!-- <span class="sidebar-nav-item">Currently v1.1.0</span> -->
  </nav>

  <div class="sidebar-item">
    <p>
      ¬© 2023. All rights reserved.
    </p>
  </div>
</div>


    <!-- Wrap is the content to shift when toggling the sidebar. We wrap the
         content to avoid any CSS collisions with our real content. -->
      <div class="wrap">
      <div class="masthead">
        <div class="container">
          <h3 class="masthead-title">
            <a href="/" title="Home">Wenhao Deng</a>
            <small></small>
          </h3>
          
          <!-- New Dark Mode Checkbox and Toggle -->
          <input type="checkbox" class="dark-mode-checkbox" id="dark-mode-checkbox">
          <label for="dark-mode-checkbox" class="dark-mode-toggle">üåû</label>
        </div>
      </div>
        

      <div class="container content">
        <div class="post">
  <h1 class="post-title">Limitation of ChatGPT in Causal Inference</h1>
  <span class="post-date">30 Mar 2023</span>
  <span class="post-subtitle">The Limitations of GPT in Causal Inference: A Dialogue with Judea Pearl and Jim Fan</span>

  <button id="toggle-toc" class="toc-button">üìñ Toggle Table of Contents</button>

  <div id="toc-container" class="article-toc">
    <ul id="toc" class="toc__list">
<li class="toc__item toc-h2"><a href="#judea-pearls-critique">Judea Pearl‚Äôs Critique</a></li>
<li class="toc__item toc-h2"><a href="#jim-fans-perspective">Jim Fan‚Äôs Perspective</a></li>
<li class="toc__item toc-h2"><a href="#the-inherent-limitations-of-gpt">The Inherent Limitations of GPT</a></li>
<li class="toc__item toc-h2"><a href="#a-cautious-approach-to-causal-inference">A Cautious Approach to Causal Inference</a></li>
</ul>
  </div>

  <p>In the realm of artificial intelligence, the ability to understand and reason about causality has always been a significant challenge. In a recent exchange on Twitter, Turing Prize Laureate Judea Pearl and AI enthusiast Jim Fan discussed the limitations of GPT, a state-of-the-art language model, in inferring causal relationships.</p>

<p><img src="/public/img/2023-03-30-Limitation-ChatGPT-Causal-Inference/tweet_screen_shot_20230331.png" alt="img"></p>

<p><a href="https://twitter.com/yudapearl/status/1641386266595033088">tweet_link</a></p>

<h2 id="judea-pearls-critique">Judea Pearl‚Äôs Critique</h2>
<p>According to Judea Pearl, deep learning models like GPT are inherently limited in their ability to reason about causality. He argues that their achievements amount to little more than ‚Äúcurve fitting‚Äù and are constrained by the passive data they are trained on. Pearl posits that answering causal questions requires either causal assumptions or interventional experiments to enrich the data.</p>

<h2 id="jim-fans-perspective">Jim Fan‚Äôs Perspective</h2>
<p>Jim Fan, on the other hand, highlights GPT‚Äôs impressive performance in reasoning about ‚Äúwhy‚Äù (cause and effect) and ‚Äúwhat if‚Äù (counterfactual imagination). He suggests that GPT‚Äôs ability to infer causality could be attributed to:</p>

<ul>
  <li>The presence of causal examples and counterfactuals in the pre-training data.</li>
  <li>Inductive reasoning based on common sense.</li>
  <li>Language pattern matching.</li>
  <li>Heuristics applied to novel cases.</li>
</ul>

<h2 id="the-inherent-limitations-of-gpt">The Inherent Limitations of GPT</h2>
<p>While GPT demonstrates some ability to reason about causality, it is important to recognize its inherent limitations. As an AI language model, GPT is unable to directly manipulate variables or actively collect new data to validate its causal inferences. Instead, it relies on the causal assumptions and human judgments present in its training data.</p>

<p>One example of this limitation can be seen in a hypothetical scenario where GPT is trained on a dataset containing the false statement: ‚ÄúJumping from a building won‚Äôt kill you because it‚Äôs from the tenth floor.‚Äù In this case, GPT might take this erroneous story as a causal assumption and generate incorrect inferences when answering related questions. Since GPT lacks the ability to interact with the real world and conduct interventional experiments, it cannot validate or correct its understanding of the causal relationship.</p>

<h2 id="a-cautious-approach-to-causal-inference">A Cautious Approach to Causal Inference</h2>
<p>In light of these limitations, it is essential to exercise caution when using GPT or similar models for causal inference. To obtain more accurate results, it may be necessary to combine GPT‚Äôs output with correct causal assumptions or conduct interventional experiments where possible.</p>

<p>In conclusion, the dialogue between Judea Pearl and Jim Fan serves as a valuable reminder of the limitations of deep learning models like GPT in the domain of causal inference. While these models have made significant strides in various aspects of natural language understanding, their abilities in causal reasoning remain constrained by their training data and the algorithms themselves.</p>


</div>


<div class="related">
  <h2>Related posts</h2>
  <ul class="related-posts">
    
      <li>
        <h3>
          <a href="/2023/03/31/HR-MRR-NDCG-Torchmetric-Implementation/">
            HR, NDCG, and MRR: An easy implementation with TorchMetrics
            <small>31 Mar 2023</small>
          </a>
        </h3>
      </li>
    
      <li>
        <h3>
          <a href="/2023/03/29/Falsificationism-and-Bayesianism/">
            Falsificationism and Bayesianism
            <small>29 Mar 2023</small>
          </a>
        </h3>
      </li>
    
  </ul>
</div>


<!-- JavaScript to toggle TOC -->
<script>
  document.addEventListener('DOMContentLoaded', (event) => {
    const tocContainer = document.getElementById('toc-container');
    const toggleButton = document.getElementById('toggle-toc');

    toggleButton.addEventListener('click', () => {
      if (tocContainer.style.display === 'none') {
        tocContainer.style.display = 'block';
      } else {
        tocContainer.style.display = 'none';
      }
    });
  });
</script>



      </div>
    </div>

    <label for="sidebar-checkbox" class="sidebar-toggle"></label>

    <!-- Your existing JavaScript -->
    <script src="/public/js/script.js"></script>

    <!-- JavaScript for Dark Mode Toggle -->
    <script>
      document.addEventListener('DOMContentLoaded', (event) => {
        const darkModeCheckbox = document.getElementById('dark-mode-checkbox');
        const darkModeToggle = document.querySelector('.dark-mode-toggle');
        
        // Initialize based on localStorage
        if (localStorage.getItem('theme') === 'dark') {
          document.documentElement.setAttribute('data-theme', 'dark');
          darkModeCheckbox.checked = true;
          darkModeToggle.textContent = 'üåù';
        }
      
        darkModeCheckbox.addEventListener('change', function () {
          if (this.checked) {
            document.documentElement.setAttribute('data-theme', 'dark');
            localStorage.setItem('theme', 'dark');
            darkModeToggle.textContent = 'üåù';
          } else {
            document.documentElement.setAttribute('data-theme', 'light');
            localStorage.setItem('theme', 'light');
            darkModeToggle.textContent = 'üåû';
          }
        });
      });
    </script>

  </body>
</html>
