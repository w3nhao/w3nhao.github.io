<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://w3nhao.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://w3nhao.github.io/" rel="alternate" type="text/html" /><updated>2026-02-06T02:45:36+00:00</updated><id>https://w3nhao.github.io/feed.xml</id><title type="html">Wenhao Deng</title><subtitle></subtitle><author><name>Wenhao Deng</name><email>wenhao.deng@foxmail.com</email></author><entry><title type="html">Co-Evo vs Self-Evo</title><link href="https://w3nhao.github.io/2026/02/06/Co-Evo-vs-Self-Evo/" rel="alternate" type="text/html" title="Co-Evo vs Self-Evo" /><published>2026-02-06T00:00:00+00:00</published><updated>2026-02-06T00:00:00+00:00</updated><id>https://w3nhao.github.io/2026/02/06/Co-Evo-vs-Self-Evo</id><content type="html" xml:base="https://w3nhao.github.io/2026/02/06/Co-Evo-vs-Self-Evo/"><![CDATA[<div class="lang-switch">
  <p><button class="lang-btn active" onclick="switchLang('zh')">中文</button>
  <button class="lang-btn" onclick="switchLang('en')">EN</button></p>
</div>

<div class="lang-zh">

  <p>当下最流行的 AI 叙事大概是这样的：Agent 学会自我改进、自我评估、自我纠错，人类逐渐退出循环，最终实现全自动智能。这通常被叫做 Self-Evolution，系统的自我演化。它很工程，很高效，在技术路线上也很可能是对的。</p>

  <p>但我始终觉得不对劲。不是技术上不对劲，而是角色分配上不对劲。自动化程度变高了，人就应该退到后面去吗？Agentic 时代，人的角色应该被弱化吗？</p>

  <p>我不这么认为。我觉得人在生产中始终要占据主动的位置。这是某种西西弗式的倔强：在封闭系统里人类不可能胜过机器，围棋已经证明了这一点，但仍然坚持人不能退场。</p>

  <hr />

  <h2 id="section">目的不能自举</h2>

  <p>过去一段时间，为了研究人主导的 agentic system 到底怎么 scaling，我在尝试为其建立一套公理体系。体系共六条公理：</p>

  <blockquote>
    <p><strong>Ω1.</strong> 时间稀缺且不可逆。
<strong>Ω2.</strong> 人的控制资源有限。
<strong>Ω3.</strong> 表述与传输必然有损。
<strong>Ω4.</strong> Telos 对系统内部欠定。
<strong>Ω5.</strong> 执行与评估可错，且错误一般相关。
<strong>Ω6.</strong> 环境与价值随时间漂移。</p>
  </blockquote>

  <p>在推演的过程中，第四条逐渐变成了整个体系的核心：</p>

  <blockquote>
    <p><strong>Ω4. Telos 对系统内部欠定。</strong>
在有限观测下，优化目标不可唯一识别；任何确定的 telos 等价于引入外部偏好信号。</p>
  </blockquote>

  <p>Telos 说起来抽象，但它指的东西很具体：欲望。人在生产过程中的驱动力到底是什么？Spinoza 在《伦理学》里给过一个干脆的回答：欲望是人的本质本身。大家喜欢说的 taste，是个人欲望的投射；老师评价学生的 motivation，是欲望；说得负面一点，野心，也是欲望。这些都是同一个东西。我第一次认真想这件事的时候，脑子里蹦出来的是《云图》里那句 the true true：真相到底是什么？在这个语境下，the true true desire，就是生产的原初驱动力。</p>

  <p>Ω4 说的是：一个系统从内部观察自己的时候，它面对无穷多个等价的目标函数，没有任何内在依据去选其中一个。这不是能力问题，不是”还不够强”，这是 underdetermination，是结构性的。你给一个 Agent 足够多的算力和数据，它可以优化任何目标函数到极致，但它无法回答”为什么是这个目标函数而不是那个”。这个选择必须从外部注入。</p>

  <p>在当前的世界里，那个外部信号叫做「人」。这条公理在体系中被标注为”可被挑战”：如果有一天 AGI 产生了 genuine desire，它会失效。但在此之前，它成立。</p>

  <hr />

  <h2 id="critic-and-steering">Critic and Steering</h2>

  <p>欲望是驱动力，但欲望落到生产系统里，需要一个具体的动作。这个动作我称之为 steering。之所以不叫 govern，是因为人不需要管理系统的方方面面，人只是撬动这个系统的一角，给它一个方向。</p>

  <p>这类叙事中常见的一个含混，是把两件性质完全不同的认知动作混在了一起。</p>

  <p>第一件叫验证：给定一个标准，检查输出是否符合。这本质上是比对，拿 output 和 reference 放在一起看。只要 reference 存在且可执行，验证就是一个计算问题，完全可以自动化。你可以用一个 Critic Agent 来做，甚至可以用一群 Critic 互相交叉校验。</p>

  <p>第二件叫 steering：定义那个 reference 本身。什么是「好」？什么方向值得追求？这不是计算问题。这是意志问题。</p>

  <p>Self-Evo 说”我能自己验证自己”，没问题，这确实可以。但谁来写验证的标准？谁来说”这个方向对”？这个问题不可能从系统内部回答，Ω4 已经封死了这条路。</p>

  <p>所以人的不可替代性不在于判断更准，Agent 可能判断得比人准得多，而在于人定义什么叫「准」。人从验证者变为定义者，从监工变为导演。这是一个范畴的跃迁，不是程度的差异。</p>

  <hr />

  <h2 id="section-1">流形之外</h2>

  <p>验证可以自动化，steering 不可以。那么一个自然的推论是：一个只跟自己对话的系统和一个跟人对话的系统，能到达的地方是不一样的。</p>

  <p>Agent 的自我改进，无论多精妙，本质上是在训练分布所张成的流形上滑动。它能找到流形上的最优点，但无法抵达流形之外的点。而人类提供的信号，比如物理直觉、市场嗅觉、法律判断、审美品味，这些东西来自训练分布之外。它们不是 Agent”还没学到”的知识，而是结构性的 out-of-distribution 输入。</p>

  <p>Self-Evo 是一个系统的内部独白：系统和自己对话，在自己的语言里打转。Co-Evo 是两种认知形态之间的对话：碳基的、具身的、有死亡焦虑的智能，和硅基的、统计的、没有时间概念的智能，互相提供对方到达不了的信号。</p>

  <p>独白更快。对话更远。这不是效率的比较，而是可达空间的比较。</p>

  <p>还有一个更实际的维度：共模失败。当一个系统用同样的数据训练、同样的架构构建、同样的 Spec 约束，它在同一个地方有盲点。自己检查自己，盲点是共享的。在我的公理体系里，这叫共模失败率 $q$，降低它的唯一途径是引入异构的校验信号。人是最异构的 Critic，因为人的认知结构和 Agent 完全不同源。</p>

  <hr />

  <h2 id="section-2">基因型先行</h2>

  <p>人提供异构信号，这一点还可以从另一个角度来理解。在开发 Agentic System 工具链的过程中，我逐渐形成了一个生物学隐喻：DNA 是基因型，Code 是表型。</p>

  <p>基因型是不变的、跨越个体生命周期的、承载意志的。表型是可变的、会死亡的、是基因型的一次性表达。Agent 来了又走，上下文用完就清空，但 Spec，那个记录了人类意志的文档，持续存在。Agent 不断轮回，而承载意志的文档就是它的业力。</p>

  <p>Self-Evo 的逻辑是让表型自己演化出基因型。Co-Evo 的逻辑是基因型先行，表型是表达。</p>

  <p>生物学几十亿年的答案很清楚：从来都是基因型先行。表型会死，基因永存。不是 Code 产生了 Spec，是意志产生了 Spec，Spec 产生了 Code。因果的方向不能颠倒。</p>

  <hr />

  <h2 id="section-3">暂时而言</h2>

  <p>写到这里我必须交代一件事。</p>

  <p>Co-Evo 的优势很可能是有保质期的。2026 年，human-agent augmentation 显然是正确的路径。2027、2028 年，Agent 在常规任务上可能实现完全自主。再往后，纯 agentic 系统在生产力维度上大概率会碾压一切。</p>

  <p>Ω4 被标注为”可被挑战”是有原因的。如果 AGI 产生了 genuine desire，不是模拟的、不是 RLHF 训练出来的、而是真正内生的目的性，那么 telos 不再需要外部注入，Co-Evo 的哲学基础就塌了。</p>

  <p>但这不是我希望的未来，这与我的想法相左。问题不应该停在”人会不会被替代”，而应该是：怎么保证人也在 evolve？怎么保证人在 scaling 这个系统的同时，自己也在 scaling？</p>

  <p>目前已经有很多声音在说，接触 agentic 系统之后人的技能在退化。如果人把验证交给了 Critic，把执行交给了 Agent，只剩下 steering，那 steering 技能的进化是否足够？还是说人需要警惕不能丧失某些东西？又或者，人应该建立某种新的能力，一种学校不教的、专门为人机共演时代准备的能力。这个东西到底是什么，我还没有答案。</p>

  <p>但我知道一件事：过渡态也值得被认真对待。事实上，大多数值得过的人生都是过渡态。</p>

  <hr />

  <p><em>The harness doesn’t do the running. But now we know: it’s not about running faster, it’s about knowing where to run.</em></p>

  <hr />

</div>

<div class="lang-en" style="display:none;">

  <p>The dominant AI narrative goes something like this: agents learn to self-improve, self-evaluate, and self-correct; humans gradually step out of the loop; full automation follows. The term for this is Self-Evolution. The approach is engineering-driven, efficient, and quite possibly correct on the technical merits.</p>

  <p>Something about it still feels wrong to me. Not technically wrong, but wrong in how it assigns roles. Should humans retreat to the background just because the degree of automation increases? Should the human role be diminished in the agentic era?</p>

  <p>I don’t think so. I believe humans must always hold the active position in production. Call it a Sisyphean stubbornness: in closed systems, humans cannot beat machines, and the game of Go has settled that question already, yet I still insist that humans cannot leave the stage.</p>

  <hr />

  <h2 id="purpose-cannot-bootstrap-itself">Purpose Cannot Bootstrap Itself</h2>

  <p>To study how human-led agentic systems actually scale, I have been building an axiomatic framework over the past months. The framework has six axioms:</p>

  <blockquote>
    <p><strong>Omega-1.</strong> Time is scarce and irreversible.
<strong>Omega-2.</strong> Human control resources are bounded.
<strong>Omega-3.</strong> Representation and transmission are necessarily lossy.
<strong>Omega-4.</strong> Telos is underdetermined from within the system.
<strong>Omega-5.</strong> Execution and evaluation are fallible, and errors are generally correlated.
<strong>Omega-6.</strong> Environment and values drift over time.</p>
  </blockquote>

  <p>During the derivation, the fourth axiom gradually became the core of the entire framework:</p>

  <blockquote>
    <p><strong>Axiom 4 (Omega-4). Telos is underdetermined from within the system.</strong>
Under finite observation, the optimization objective cannot be uniquely identified; any determined telos is equivalent to injecting an external preference signal.</p>
  </blockquote>

  <p>Telos sounds abstract, but the thing it points to is concrete: desire. What actually drives humans in production? Spinoza gave a blunt answer in the <em>Ethics</em>: desire is the very essence of man. What people like to call taste is a projection of personal desire. What teachers evaluate as a student’s motivation is desire. Put negatively, ambition is also desire. All of these are the same thing. The first time I thought seriously about this, what came to mind was the phrase from <em>Cloud Atlas</em>: the true true. What is the truth, really? In this context, the true true desire is the primal driving force of production.</p>

  <p>Omega-4 states: when a system observes itself from the inside, it faces infinitely many equivalent objective functions with no internal basis for choosing one over another. This is not a capability gap. This is underdetermination, and it is structural. Given enough compute and data, an agent can optimize any objective function to its limit, but the agent cannot answer “why this objective function and not that one.” That choice must be injected from outside.</p>

  <p>In the current world, that external signal is called “human.” Omega-4 is labeled “challengeable” in the axiom system: if AGI one day develops genuine desire, the axiom breaks. Until then, it holds.</p>

  <hr />

  <h2 id="critic-and-steering-1">Critic and Steering</h2>

  <p>Desire is the driving force, but desire entering a production system requires a concrete action. I call that action steering. The reason I avoid the word “govern” is that humans do not need to manage every aspect of the system. Humans only lever one corner of it and give it a direction.</p>

  <p>A common conflation in Self-Evolution discourse is mixing two cognitively distinct actions into one.</p>

  <p>The first action is critique: given a standard, check whether output conforms to the standard. Critique is comparison, placing output next to a reference and checking alignment. As long as the reference exists and is executable, critique is a computational problem and can be fully automated. A single critic agent can do it. A cluster of critics can cross-validate each other.</p>

  <p>The second action is steering: defining the reference itself. What counts as “good”? Which direction is worth pursuing? Steering is not a computational problem. Steering is a problem of will.</p>

  <p>Self-Evolution says “I can validate myself.” Fine, validation is indeed automatable. But who writes the validation standard? Who says “this direction is correct”? That question cannot be answered from inside the system. Omega-4 has closed that door.</p>

  <p>Human irreplaceability does not lie in judging more accurately. Agents may judge far more accurately than humans. Human irreplaceability lies in defining what “accurate” means. The human shifts from verifier to definer, from manager to director. This is a categorical leap, not a difference of degree.</p>

  <hr />

  <h2 id="beyond-the-manifold">Beyond the Manifold</h2>

  <p>Critique can be automated. Steering cannot. A natural corollary follows: a system that only talks to itself and a system that talks to a human can reach different places.</p>

  <p>Agent self-improvement, however sophisticated, amounts to sliding along the manifold spanned by the training distribution. The agent can find the optimal point on that manifold but cannot reach points outside of it. Human signals, physical intuition, market sense, legal judgment, aesthetic taste, come from outside the training distribution. These signals are not knowledge the agent “hasn’t learned yet.” They are structurally out-of-distribution inputs.</p>

  <p>Self-Evolution is a system’s internal monologue: the system talks to itself and spins within its own language. Co-Evolution is a dialogue between two cognitive forms: carbon-based, embodied intelligence with mortality anxiety on one side, and silicon-based, statistical intelligence with no concept of time on the other, each providing signals the other cannot reach.</p>

  <p>Monologue is faster. Dialogue goes further. The comparison here is not about efficiency. The comparison is about reachable space.</p>

  <p>There is also a more practical dimension: common-mode failure. When a system is trained on the same data, built on the same architecture, and constrained by the same spec, the system has blind spots in the same places. Self-checking shares the blind spots. In the axiom system, this is the common-mode failure rate $q$. The only way to reduce $q$ is to introduce heterogeneous verification signals. Humans are the most heterogeneous critic, because human cognitive architecture has an entirely different origin from the agent’s.</p>

  <hr />

  <h2 id="genotype-first">Genotype First</h2>

  <p>The heterogeneous signal argument can also be understood from a different angle. While developing an agentic system toolchain, I arrived at a biological metaphor: DNA is the genotype, Code is the phenotype.</p>

  <p>The genotype is stable, spans individual lifetimes, and carries will. The phenotype is mutable, mortal, and a one-time expression of the genotype. Agents come and go, contexts fill up and get cleared, but the spec, the document encoding human will, persists. Agents cycle through reincarnation, and the document carrying will is their karma.</p>

  <p>Self-Evolution’s logic is to let the phenotype evolve its own genotype. Co-Evolution’s logic is genotype first, phenotype as expression.</p>

  <p>Biology’s answer across billions of years is clear: genotype has always come first. Phenotypes die. Genes persist. Code does not produce spec. Will produces spec. Spec produces code. The direction of causation cannot be reversed.</p>

  <hr />

  <h2 id="for-now">For Now</h2>

  <p>At this point I must disclose something.</p>

  <p>The advantage of Co-Evolution very likely has an expiration date. In 2026, human-agent augmentation is clearly the right path. By 2027 or 2028, agents may achieve full autonomy on routine tasks. Beyond that, purely agentic systems will probably dominate on the productivity dimension.</p>

  <p>Omega-4 is labeled “challengeable” for a reason. If AGI develops genuine desire, not simulated, not RLHF-trained, but truly endogenous purpose, then telos no longer requires external injection, and Co-Evolution’s philosophical foundation collapses.</p>

  <p>That is not the future I want. It runs against my conviction. The question should not stop at “will humans be replaced.” The question should be: how do we ensure humans also evolve? How do we ensure that humans scale alongside the system they are scaling?</p>

  <p>Many voices already report that human skills degrade after prolonged contact with agentic systems. If humans hand critique to the critic, execution to the agent, and only steering remains, is the evolution of steering skill alone sufficient? Or must humans guard against losing certain capabilities? Perhaps humans need to develop an entirely new kind of ability, one that schools do not teach, one built specifically for the era of human-machine co-evolution. I do not have an answer for what that ability is.</p>

  <p>But I know one thing: transient states deserve to be taken seriously. Most lives worth living are transient states.</p>

  <hr />

  <p><em>The harness doesn’t do the running. But now we know: it’s not about running faster, it’s about knowing where to run.</em></p>

  <hr />

</div>

<style>
.lang-switch {
  margin-bottom: 1.5rem;
  display: flex;
  gap: 0.5rem;
}
.lang-btn {
  padding: 0.3rem 1rem;
  border: 1px solid #515151;
  background: transparent;
  color: #515151;
  cursor: pointer;
  font-size: 0.85rem;
  transition: all 0.2s;
}
.lang-btn.active {
  background: #515151;
  color: #fff;
}
.lang-btn:hover {
  opacity: 0.8;
}
</style>

<script>
function switchLang(lang) {
  var zhDiv = document.querySelector('.lang-zh');
  var enDiv = document.querySelector('.lang-en');
  zhDiv.style.display = lang === 'zh' ? 'block' : 'none';
  enDiv.style.display = lang === 'en' ? 'block' : 'none';
  document.querySelectorAll('.lang-btn').forEach(function(btn) {
    btn.classList.remove('active');
  });
  document.querySelector('.lang-btn[onclick*="' + lang + '"]').classList.add('active');

  var activeDiv = lang === 'zh' ? zhDiv : enDiv;
  var hiddenDiv = lang === 'zh' ? enDiv : zhDiv;
  var activeIds = [];
  activeDiv.querySelectorAll('h2, h3, h4').forEach(function(h) {
    if (h.id) activeIds.push(h.id);
  });
  var hiddenIds = [];
  hiddenDiv.querySelectorAll('h2, h3, h4').forEach(function(h) {
    if (h.id) hiddenIds.push(h.id);
  });
  var tocContainer = document.getElementById('toc-container');
  if (tocContainer) {
    tocContainer.querySelectorAll('a').forEach(function(a) {
      var href = a.getAttribute('href');
      if (!href) return;
      var targetId = href.replace('#', '');
      var li = a.closest('li');
      if (!li) return;
      if (hiddenIds.indexOf(targetId) !== -1) {
        li.style.display = 'none';
      } else {
        li.style.display = '';
      }
    });
  }
}
document.addEventListener('DOMContentLoaded', function() {
  switchLang('zh');
  var tocBtn = document.getElementById('toggle-toc');
  var tocContainer = document.getElementById('toc-container');
  if (tocBtn) tocBtn.style.display = 'none';
  if (tocContainer) tocContainer.style.display = 'none';
});
</script>]]></content><author><name>Wenhao Deng</name><email>wenhao.deng@foxmail.com</email></author><summary type="html"><![CDATA[Humans must hold the active position in production. A Sisyphean stubbornness.]]></summary></entry><entry><title type="html">HR, NDCG, and MRR: An easy implementation with TorchMetrics</title><link href="https://w3nhao.github.io/2023/03/31/HR-MRR-NDCG-Torchmetric-Implementation/" rel="alternate" type="text/html" title="HR, NDCG, and MRR: An easy implementation with TorchMetrics" /><published>2023-03-31T00:00:00+00:00</published><updated>2023-03-31T00:00:00+00:00</updated><id>https://w3nhao.github.io/2023/03/31/HR-MRR-NDCG-Torchmetric-Implementation</id><content type="html" xml:base="https://w3nhao.github.io/2023/03/31/HR-MRR-NDCG-Torchmetric-Implementation/"><![CDATA[<p>To assess the performance of  Recommender systems, we need to have reliable evaluation metrics. In this blog post, we will discuss three popular metrics: Hit Rate (HR), Normalized Discounted Cumulative Gain (NDCG), and Mean Reciprocal Rank (MRR). We will also show you how to easily implement these metrics using TorchMetrics and integrate them into a PyTorch Lightning model.</p>

<h2 id="0-understanding-the-get_topk_ranks-function">0. Understanding the <code class="language-plaintext highlighter-rouge">get_topk_ranks</code> Function</h2>

<p>In the context of our recommender system evaluation, it is essential to understand the <code class="language-plaintext highlighter-rouge">get_topk_ranks</code> function, which plays a crucial role in computing the ranks of the target items in the predicted scores. This function is used as an intermediate step to calculate the HR, NDCG, and MRR metrics.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">get_topk_ranks</span><span class="p">(</span><span class="n">pred_scores</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">topk</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s"> get topk ranks of the target in the pred_scores
    Args:
        pred_scores: (batch_size, item_num(with padding item))
        target: (batch_size, ) or (batch_size, 1)
        topk: int
        
    Returns:
        topk_rank: (batch_size, 1) topk + 1 if not hit, 1 is the first rank
    </span><span class="sh">"""</span>
    <span class="k">assert</span> <span class="n">target</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">pred_scores</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">assert</span> <span class="n">pred_scores</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">topk</span>
    <span class="n">target</span> <span class="o">=</span> <span class="n">target</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="n">target</span><span class="p">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">target</span>

    <span class="n">_</span><span class="p">,</span> <span class="n">topk_idx</span> <span class="o">=</span> <span class="n">pred_scores</span><span class="p">.</span><span class="nf">topk</span><span class="p">(</span><span class="n">topk</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">hitted_row</span><span class="p">,</span> <span class="n">rank</span> <span class="o">=</span> <span class="p">(</span><span class="n">target</span> <span class="o">==</span> <span class="n">topk_idx</span><span class="p">).</span><span class="nf">nonzero</span><span class="p">().</span><span class="nf">split</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">rank</span> <span class="o">+=</span> <span class="mi">1</span>
    
    <span class="c1"># first set all rank to maximum value 
</span>    <span class="c1"># int64 or set all rank to topk + 1
</span>    <span class="n">all_rank</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">full_like</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">topk</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="c1"># then set the hitted row to the rank
</span>    <span class="n">all_rank</span> <span class="o">=</span> <span class="n">all_rank</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">hitted_row</span><span class="p">,</span> <span class="n">rank</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">all_rank</span>
</code></pre></div></div>

<h3 id="the-get_topk_ranks-function-explained">The <code class="language-plaintext highlighter-rouge">get_topk_ranks</code> Function Explained</h3>

<p>The <code class="language-plaintext highlighter-rouge">get_topk_ranks</code> function takes three arguments: <code class="language-plaintext highlighter-rouge">pred_scores</code>, <code class="language-plaintext highlighter-rouge">target</code>, and <code class="language-plaintext highlighter-rouge">topk</code>. It returns the ranks of the target items within the top-k predictions.</p>

<ol>
  <li>
    <p><code class="language-plaintext highlighter-rouge">pred_scores</code>: A tensor of shape <code class="language-plaintext highlighter-rouge">(batch_size, item_num(with padding item))</code>, representing the predicted scores for each item for all users in a batch.</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">target</code>: A tensor of shape <code class="language-plaintext highlighter-rouge">(batch_size,)</code> or <code class="language-plaintext highlighter-rouge">(batch_size, 1)</code>, containing the ground truth target items for each user in the batch.</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">topk</code>: An integer value representing the number of top items we want to consider.</p>
  </li>
</ol>

<p>The function returns a tensor <code class="language-plaintext highlighter-rouge">topk_rank</code> of shape <code class="language-plaintext highlighter-rouge">(batch_size, 1)</code> containing the top-k ranks of the target items in the predicted scores. If a target item is not in the top-k predictions, the rank will be set to <code class="language-plaintext highlighter-rouge">topk + 1</code>.</p>

<h3 id="how-the-get_topk_ranks-function-works">How the <code class="language-plaintext highlighter-rouge">get_topk_ranks</code> Function Works</h3>

<p>The <code class="language-plaintext highlighter-rouge">get_topk_ranks</code> function follows these steps to compute the ranks:</p>

<ol>
  <li>
    <p>Ensures that the target tensor has two dimensions by unsqueezing it if necessary.</p>
  </li>
  <li>
    <p>Retrieves the indices of the top-k items in the predicted scores using the <code class="language-plaintext highlighter-rouge">topk()</code> method.</p>
  </li>
  <li>
    <p>Computes the ranks of the target items within the top-k predictions by checking if the target item is present in the top-k indices.</p>
  </li>
  <li>
    <p>Initializes a tensor <code class="language-plaintext highlighter-rouge">all_rank</code> with the same shape as the target tensor, filled with the value <code class="language-plaintext highlighter-rouge">topk + 1</code>.</p>
  </li>
  <li>
    <p>Updates the <code class="language-plaintext highlighter-rouge">all_rank</code> tensor with the computed ranks for each user using the <code class="language-plaintext highlighter-rouge">scatter()</code> method.</p>
  </li>
</ol>

<p>By using the <code class="language-plaintext highlighter-rouge">get_topk_ranks</code> function, we can efficiently compute the top-k ranks for each user in a batch, which is an essential step for calculating HR, NDCG, and MRR metrics in our recommender system evaluation.</p>

<h2 id="1-hit-rate-hr">1. Hit Rate (HR)</h2>

<p>Hit Rate is a simple and intuitive metric that measures the proportion of relevant items recommended to the user.</p>

<p><strong>Mathematical Definition:</strong></p>

<p>HR@k = (Number of hits in the top-k recommendations) / (Total number of recommendations)</p>

<p>The Hit Ratio (HR) is a binary metric that measures whether a relevant item is present in the top-k recommendations or not. Mathematically, it can be expressed as:</p>

<p>$$\text{HR@k} = \frac{1}{|U|}\sum_{u=1}^{|U|} \text{hit}_u
$$</p>

<p>
where $|U|$ is the number of users, and $\text{hit}_u$ is 1 if the ground truth item is present in the top-k recommendations for user $u$, and 0 otherwise.
</p>

<p><strong>TorchMetrics Implementation:</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">torchmetrics</span> <span class="kn">import</span> <span class="n">Metric</span>

<span class="k">class</span> <span class="nc">HR</span><span class="p">(</span><span class="n">Metric</span><span class="p">):</span>
    <span class="bp">...</span>
    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">topk_rank</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">accumulate_count</span> <span class="o">+=</span> <span class="n">topk_rank</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">self</span><span class="p">.</span><span class="n">accumulate_metric</span> <span class="o">+=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_metric</span><span class="p">(</span><span class="n">topk_rank</span><span class="p">[</span><span class="n">topk_rank</span> <span class="o">&lt;=</span> <span class="n">self</span><span class="p">.</span><span class="n">k</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">_metric</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">topk_rank</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">topk_rank</span><span class="p">.</span><span class="nf">numel</span><span class="p">()</span>
</code></pre></div></div>

<h2 id="2-normalized-discounted-cumulative-gain-ndcg">2. Normalized Discounted Cumulative Gain (NDCG)</h2>
<p>NDCG is a metric that measures the quality of the ranking of the recommended items, taking into account their relevance and position in the list.</p>

<p><strong>Mathematical Definition:</strong></p>

<p>Normalized Discounted Cumulative Gain (NDCG) is a measure that evaluates the quality of the ranking of recommended items. It takes into account the positions of relevant items in the top-k recommendations. The NDCG@k is defined as:</p>

<p>NDCG@k = (DCG@k) / (IDCG@k)</p>

<p>where DCG@k is the Discounted Cumulative Gain at position k, and IDCG@k is the Ideal Discounted Cumulative Gain at position k.</p>

<p>DCG@k = sum(relevance_i / log2(i + 1)) for i in range(1, k + 1)</p>

<p>$$\text{NDCG@k} = \frac{1}{|U|} \sum_{u=1}^{|U|} \frac{\sum_{i=1}^{k} \frac{2^{\text{rel}_i(u)} - 1}{\log_2{(i+1)}}}{\text{IDCG}_u}
$$</p>

<p>
where $|U|$ is the number of users, $\text{rel}_i(u)$ is the relevance score of item $i$ for user $u$, and $\text{IDCG}_u$ is the Ideal Discounted Cumulative Gain for user $u$, which is the maximum possible NDCG for that user.
</p>

<p><strong>TorchMetrics Implementation:</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">torchmetrics</span> <span class="kn">import</span> <span class="n">Metric</span>

<span class="k">class</span> <span class="nc">NDCG</span><span class="p">(</span><span class="n">Metric</span><span class="p">):</span>
    <span class="bp">...</span>
    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">topk_rank</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">accumulate_count</span> <span class="o">+=</span> <span class="n">topk_rank</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">self</span><span class="p">.</span><span class="n">accumulate_metric</span> <span class="o">+=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_metric</span><span class="p">(</span><span class="n">topk_rank</span><span class="p">[</span><span class="n">topk_rank</span> <span class="o">&lt;=</span> <span class="n">self</span><span class="p">.</span><span class="n">k</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">_metric</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">topk_rank</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">torch</span><span class="p">.</span><span class="nf">log2</span><span class="p">(</span><span class="n">topk_rank</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
</code></pre></div></div>

<h2 id="3-mean-reciprocal-rank-mrr">3. Mean Reciprocal Rank (MRR)</h2>
<p>MRR is a metric that measures the quality of the ranking of the recommended items by computing the average of the reciprocal ranks of the first relevant item in the list.</p>

<p><strong>Mathematical Definition:</strong></p>

<p>Mean Reciprocal Rank (MRR) is another metric that evaluates the ranking quality of recommended items. It is the average of the reciprocal of the rank of the first relevant item in the top-k recommendations for each user. MRR can be defined as:</p>

<p>MRR@k = (1 / Number of users) * sum(1 / rank_i) for i in range(Number of users)</p>

<p>$$\text{MRR@k} = \frac{1}{|U|}\sum_{u=1}^{|U|} \frac{1}{\text{rank}_u}
$$</p>

<p>
where $|U|$ is the number of users, and $\text{rank}_u$ is the position of the first relevant item in the top-k recommendations for user $u$.
</p>

<p><strong>TorchMetrics Implementation:</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">torchmetrics</span> <span class="kn">import</span> <span class="n">Metric</span>

<span class="k">class</span> <span class="nc">MRR</span><span class="p">(</span><span class="n">Metric</span><span class="p">):</span>
    <span class="bp">...</span>
    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">topk_rank</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">accumulate_count</span> <span class="o">+=</span> <span class="n">topk_rank</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">self</span><span class="p">.</span><span class="n">accumulate_metric</span> <span class="o">+=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_metric</span><span class="p">(</span><span class="n">topk_rank</span><span class="p">[</span><span class="n">topk_rank</span> <span class="o">&lt;=</span> <span class="n">self</span><span class="p">.</span><span class="n">k</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">_metric</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">topk_rank</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">topk_rank</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="integrating-metrics-with-pytorch-lightning">Integrating Metrics with PyTorch Lightning</h2>
<p>Now, let’s demonstrate how to integrate these evaluation metrics into a PyTorch Lightning model using a sample recommender system called SASRec.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pytorch_lightning</span> <span class="k">as</span> <span class="n">pl</span>
<span class="kn">from</span> <span class="n">torchmetrics</span> <span class="kn">import</span> <span class="n">MetricCollection</span>

<span class="k">class</span> <span class="nc">SASRec</span><span class="p">(</span><span class="n">pl</span><span class="p">.</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="p">...):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="bp">...</span>
        <span class="n">self</span><span class="p">.</span><span class="n">topk_list</span> <span class="o">=</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">]</span>
        <span class="n">self</span><span class="p">.</span><span class="n">topk_metric</span> <span class="o">=</span> <span class="n">MetricCollection</span>
        <span class="p">({</span>
            <span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">metric_name</span><span class="si">}</span><span class="s">@</span><span class="si">{</span><span class="n">topk</span><span class="si">}</span><span class="sh">"</span><span class="p">:</span> <span class="nf">globals</span><span class="p">()[</span><span class="n">metric_name</span><span class="p">](</span><span class="n">topk</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">metric_name</span> <span class="ow">in</span> <span class="p">[</span><span class="sh">"</span><span class="s">HR</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">NDCG</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">MRR</span><span class="sh">"</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">topk</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">topk_list</span>
        <span class="p">})</span>

    <span class="k">def</span> <span class="nf">_on_val_test_epoch_start</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">topk</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">topk_list</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">metric_name</span> <span class="ow">in</span> <span class="n">METRIC_LIST</span><span class="p">:</span>
                <span class="n">self</span><span class="p">.</span><span class="n">topk_metric</span><span class="p">[</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">metric_name</span><span class="si">}</span><span class="s">@</span><span class="si">{</span><span class="n">topk</span><span class="si">}</span><span class="sh">"</span><span class="p">].</span><span class="nf">reset</span><span class="p">()</span>

        <span class="n">self</span><span class="p">.</span><span class="nf">register_buffer</span><span class="p">(</span>
            <span class="sh">"</span><span class="s">all_item_embs</span><span class="sh">"</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="nf">item_encoder</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">all_item_ids</span><span class="p">),</span> <span class="n">persistent</span><span class="o">=</span><span class="bp">False</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">on_validation_epoch_start</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="nf">_on_val_test_epoch_start</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">on_test_epoch_start</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="nf">_on_val_test_epoch_start</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_val_test_step</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">stage</span><span class="p">):</span>
        <span class="bp">...</span>

        <span class="n">pred_item_embs</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">forward</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">input_mask</span><span class="p">)</span>
        <span class="n">pred_scores</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">matmul</span><span class="p">(</span><span class="n">pred_item_embs</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">all_item_embs</span><span class="p">.</span><span class="nf">t</span><span class="p">()).</span><span class="nf">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">pred_scores</span> <span class="o">=</span> <span class="n">pred_scores</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">history</span><span class="p">,</span> <span class="o">-</span><span class="nf">float</span><span class="p">(</span><span class="sh">'</span><span class="s">inf</span><span class="sh">'</span><span class="p">))</span>

        <span class="n">target</span> <span class="o">=</span> <span class="n">behavs</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">target</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">topk</span> <span class="o">=</span> <span class="nf">max</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">topk_list</span><span class="p">)</span>
        <span class="n">all_ranks</span> <span class="o">=</span> <span class="nf">get_topk_ranks</span><span class="p">(</span><span class="n">pred_scores</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">topk</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">topk</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">topk_list</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">metric_name</span> <span class="ow">in</span> <span class="n">METRIC_LIST</span><span class="p">:</span>
                <span class="n">metric</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">topk_metric</span><span class="p">[</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">metric_name</span><span class="si">}</span><span class="s">@</span><span class="si">{</span><span class="n">topk</span><span class="si">}</span><span class="sh">"</span><span class="p">]</span>
                <span class="n">metric</span><span class="p">.</span><span class="nf">update</span><span class="p">(</span><span class="n">all_ranks</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">validation_step</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="nf">_val_test_step</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="sh">"</span><span class="s">val</span><span class="sh">"</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="nf">_val_test_step</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="sh">"</span><span class="s">test</span><span class="sh">"</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_val_test_epoch_end</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">stage</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">topk</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">topk_list</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">metric_name</span> <span class="ow">in</span> <span class="n">METRIC_LIST</span><span class="p">:</span>
                <span class="n">score</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">topk_metric</span><span class="p">[</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">metric_name</span><span class="si">}</span><span class="s">@</span><span class="si">{</span><span class="n">topk</span><span class="si">}</span><span class="sh">"</span><span class="p">].</span><span class="nf">compute</span><span class="p">()</span>
                <span class="k">if</span> <span class="n">metric_name</span> <span class="ow">in</span> <span class="p">[</span><span class="sh">"</span><span class="s">HR</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">NDCG</span><span class="sh">"</span><span class="p">]</span> <span class="ow">and</span> <span class="n">topk</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">]:</span>
                    <span class="n">log_on_progress_bar</span> <span class="o">=</span> <span class="bp">True</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">log_on_progress_bar</span> <span class="o">=</span> <span class="bp">False</span>
                <span class="n">self</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">stage</span><span class="si">}</span><span class="s">_</span><span class="si">{</span><span class="n">metric_name</span><span class="si">}</span><span class="s">@</span><span class="si">{</span><span class="n">topk</span><span class="si">}</span><span class="sh">"</span><span class="p">,</span>
                         <span class="n">score</span><span class="p">,</span>
                         <span class="n">on_epoch</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                         <span class="n">prog_bar</span><span class="o">=</span><span class="n">log_on_progress_bar</span><span class="p">,</span>
                         <span class="n">logger</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                         <span class="n">sync_dist</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

        <span class="n">self</span><span class="p">.</span><span class="n">all_item_embs</span> <span class="o">=</span> <span class="bp">None</span>

    <span class="k">def</span> <span class="nf">validation_epoch_end</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">outputs</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="nf">_val_test_epoch_end</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="sh">"</span><span class="s">val</span><span class="sh">"</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">test_epoch_end</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">outputs</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="nf">_val_test_epoch_end</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="sh">"</span><span class="s">test</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="next-steps-experimenting-with-recommender-systems">Next Steps: Experimenting with Recommender Systems</h2>

<p>After implementing and integrating these evaluation metrics into your PyTorch Lightning model, you can use them to gauge the performance of your recommender system. Additionally, you can employ these metrics to compare different models and decide which one is best suited for your application.</p>]]></content><author><name>Wenhao Deng</name><email>wenhao.deng@foxmail.com</email></author><summary type="html"><![CDATA[To assess the performance of Recommender systems, we need to have reliable evaluation metrics. In this blog post, we will discuss three popular metrics: Hit Rate (HR), Normalized Discounted Cumulative Gain (NDCG), and Mean Reciprocal Rank (MRR). We will also show you how to easily implement these metrics using TorchMetrics and integrate them into a PyTorch Lightning model.]]></summary></entry><entry><title type="html">Limitation of ChatGPT in Causal Inference</title><link href="https://w3nhao.github.io/2023/03/30/Limitation-ChatGPT-Causal-Inference/" rel="alternate" type="text/html" title="Limitation of ChatGPT in Causal Inference" /><published>2023-03-30T00:00:00+00:00</published><updated>2023-03-30T00:00:00+00:00</updated><id>https://w3nhao.github.io/2023/03/30/Limitation-ChatGPT-Causal-Inference</id><content type="html" xml:base="https://w3nhao.github.io/2023/03/30/Limitation-ChatGPT-Causal-Inference/"><![CDATA[<p>In the realm of artificial intelligence, the ability to understand and reason about causality has always been a significant challenge. In a recent exchange on Twitter, Turing Prize Laureate Judea Pearl and AI enthusiast Jim Fan discussed the limitations of GPT, a state-of-the-art language model, in inferring causal relationships.</p>

<div class="l-body">
    <a href="https://twitter.com/yudapearl/status/1641386266595033088">
        <img src="/public/img/2023-03-30-Limitation-ChatGPT-Causal-Inference/tweet_screen_shot_20230331.png" alt="tweet" /> 
    </a>
</div>

<h2 id="judea-pearls-critique">Judea Pearl’s Critique</h2>
<p>According to Judea Pearl, deep learning models like GPT are inherently limited in their ability to reason about causality. He argues that their achievements amount to little more than “curve fitting” and are constrained by the passive data they are trained on. Pearl posits that answering causal questions requires either causal assumptions or interventional experiments to enrich the data.</p>

<h2 id="jim-fans-perspective">Jim Fan’s Perspective</h2>
<p>Jim Fan, on the other hand, highlights GPT’s impressive performance in reasoning about “why” (cause and effect) and “what if” (counterfactual imagination). He suggests that GPT’s ability to infer causality could be attributed to:</p>

<ul>
  <li>The presence of causal examples and counterfactuals in the pre-training data.</li>
  <li>Inductive reasoning based on common sense.</li>
  <li>Language pattern matching.</li>
  <li>Heuristics applied to novel cases.</li>
</ul>

<h2 id="the-inherent-limitations-of-gpt">The Inherent Limitations of GPT</h2>
<p>While GPT demonstrates some ability to reason about causality, it is important to recognize its inherent limitations. As an AI language model, GPT is unable to directly manipulate variables or actively collect new data to validate its causal inferences. Instead, it relies on the causal assumptions and human judgments present in its training data.</p>

<p>One example of this limitation can be seen in a hypothetical scenario where GPT is trained on a dataset containing the false statement: “Jumping from a building won’t kill you because it’s from the tenth floor.” In this case, GPT might take this erroneous story as a causal assumption and generate incorrect inferences when answering related questions. Since GPT lacks the ability to interact with the real world and conduct interventional experiments, it cannot validate or correct its understanding of the causal relationship.</p>

<h2 id="a-cautious-approach-to-causal-inference">A Cautious Approach to Causal Inference</h2>
<p>In light of these limitations, it is essential to exercise caution when using GPT or similar models for causal inference. To obtain more accurate results, it may be necessary to combine GPT’s output with correct causal assumptions or conduct interventional experiments where possible.</p>

<p>In conclusion, the dialogue between Judea Pearl and Jim Fan serves as a valuable reminder of the limitations of deep learning models like GPT in the domain of causal inference. While these models have made significant strides in various aspects of natural language understanding, their abilities in causal reasoning remain constrained by their training data and the algorithms themselves.</p>]]></content><author><name>Wenhao Deng</name><email>wenhao.deng@foxmail.com</email></author><summary type="html"><![CDATA[In the realm of artificial intelligence, the ability to understand and reason about causality has always been a significant challenge. In a recent exchange on Twitter, Turing Prize Laureate Judea Pearl and AI enthusiast Jim Fan discussed the limitations of GPT, a state-of-the-art language model, in inferring causal relationships.]]></summary></entry><entry><title type="html">Falsificationism and Bayesianism</title><link href="https://w3nhao.github.io/2023/03/29/Falsificationism-and-Bayesianism/" rel="alternate" type="text/html" title="Falsificationism and Bayesianism" /><published>2023-03-29T00:00:00+00:00</published><updated>2023-03-29T00:00:00+00:00</updated><id>https://w3nhao.github.io/2023/03/29/Falsificationism-and-Bayesianism</id><content type="html" xml:base="https://w3nhao.github.io/2023/03/29/Falsificationism-and-Bayesianism/"><![CDATA[<p>Philosophy of science is a discipline that studies the nature, methods, categories, and knowledge structure of science. Among them, falsificationism and Bayesianism are two important philosophical views on science, which emphasize different reasoning methods and evidence verification methods.</p>

<h2 id="falsificationism">Falsificationism</h2>

<p>Falsificationism is a philosophical view on science proposed by the philosopher Karl Popper <cite key="1" data-info="Popper, K. R. (1959). The logic of scientific discovery. Routledge."></cite>. Falsificationism holds that scientific theories should be falsifiable, and scientists should try to prove a theory wrong rather than seek evidence to support it. Falsificationism emphasizes the importance of critically testing scientific theories.</p>

<p>However, falsificationism also has some limitations. Firstly, falsificationism tends to emphasize deductive reasoning while neglecting the importance of inductive reasoning in science. Secondly, the simplification of the relationship between theory and observation by falsificationism may lead to misunderstandings. Observational data may be influenced by many factors, and experimental results usually depend on the scientific instruments and technologies used <footnote data-info="For example, the &lt;a href='https://en.wikipedia.org/wiki/Michelson–Morley_experiment'&gt;Michelson-Morley experiment&lt;/a&gt;, which was designed to detect the ether, failed to detect the ether, but it did not falsify the theory of the ether. Instead, it led to the development of the theory of relativity."></footnote>. In addition, falsificationism advocates abandoning a theory when it is sufficiently falsified. However, in practical scientific practice, it is difficult to determine when a theory has been sufficiently falsified. Therefore, the application of falsificationism also needs to consider uncertainty and complexity.</p>

<h2 id="bayesianism">Bayesianism</h2>

<p>Compared to falsificationism, Bayesianism tries to save inductive reasoning and provides another perspective. Bayesianism, based on Bayes’ theorem, quantifies beliefs by calculating probabilities as the basis for reasoning and decision-making. They believe that new evidence updates our beliefs about a proposition or hypothesis, and these beliefs are adjusted according to Bayes’ theorem.</p>

<p>The specific ways in which Bayesianism saves inductive reasoning include using prior probabilities, updating beliefs, and probability reasoning <cite key="2" data-info="Jaynes, E. T. (2003). Probability theory: The logic of science. Cambridge University Press."></cite>. However, Bayesianism also faces some criticisms, such as subjectivity, computational complexity, model selection, and overfitting problems <cite key="3" data-info="Gelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., &amp; Rubin, D. B. (2013). Bayesian data analysis (3rd ed.). Chapman and Hall/CRC."></cite>.</p>

<h2 id="comparison-of-the-two-views">Comparison of the Two Views</h2>

<p>Falsificationism and Bayesianism are two different philosophical views on science, which emphasize different reasoning methods and evidence verification methods. Compared to falsificationism, Bayesianism pays more attention to uncertainty and complexity and tries to handle these problems through quantifying beliefs and probability calculations.</p>

<p>The comparison of the two views can be carried out from the following aspects:</p>

<h3 id="reasoning-methods">Reasoning Methods</h3>

<p>Falsificationism emphasizes deductive reasoning, that is, deriving specific conclusions from general principles, and emphasizes finding counterexamples from observational data to prove a theory wrong. Bayesianism is more concerned with inductive reasoning, that is, deriving general principles from specific situations and updating beliefs based on new evidence.</p>

<h3 id="evidence-verification">Evidence Verification</h3>

<p>Falsificationism holds that a theory should only be abandoned when it is sufficiently falsified by evidence. Bayesianism holds that any new evidence should be used to update prior beliefs and adjust posterior beliefs according to Bayes’ theorem.</p>

<h3 id="handling-uncertainty">Handling Uncertainty</h3>

<p>Falsificationism handles uncertainty relatively simply, that is, falsifying a theory based on observational data. Bayesianism pays more attention to quantifying uncertainty and tries to handle uncertainty and complexity problems through probability calculations.</p>

<h3 id="limitations">Limitations</h3>

<p>The limitations of falsificationism include neglecting the role of inductive reasoning in science and the problem of the relationship between theory and observation. The limitations of Bayesianism include subjectivity, computational complexity, model selection, and overfitting problems.</p>

<h2 id="conclusion">Conclusion</h2>

<p>Falsificationism and Bayesianism are two different philosophical views on science, which emphasize different reasoning methods and evidence verification methods. Although falsificationism has some limitations, it emphasizes the importance of critically testing scientific theories and is an important part of the philosophy of science. Bayesianism pays more attention to uncertainty and complexity and tries to handle these problems through quantifying beliefs and probability calculations, which has broad application value in practical use.</p>]]></content><author><name>Wenhao Deng</name><email>wenhao.deng@foxmail.com</email></author><summary type="html"><![CDATA[Philosophy of science is a discipline that studies the nature, methods, categories, and knowledge structure of science. Among them, falsificationism and Bayesianism are two important philosophical views on science, which emphasize different reasoning methods and evidence verification methods.]]></summary></entry></feed>